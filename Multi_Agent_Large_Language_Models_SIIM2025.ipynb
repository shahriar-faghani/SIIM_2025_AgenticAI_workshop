{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "266620d475d84a5586e22d0bf21364b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f98ae51b4a054d41b432cefd5564b89e",
              "IPY_MODEL_4f24eaada87c4ee99669cab82bffde5c",
              "IPY_MODEL_477edb5350dd479e8256336d0540fcd7"
            ],
            "layout": "IPY_MODEL_e33b135c9d0e426c9bb5d8935b67493e"
          }
        },
        "f98ae51b4a054d41b432cefd5564b89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fc19181841f4efbaaa01ae1b3d3567d",
            "placeholder": "​",
            "style": "IPY_MODEL_f6d14adc46da4f75994b4bd20bb8a440",
            "value": "modules.json: 100%"
          }
        },
        "4f24eaada87c4ee99669cab82bffde5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343af3fa46b442aba6d569efe2b26460",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_acc84c4704e24800808ddc94fe38411e",
            "value": 349
          }
        },
        "477edb5350dd479e8256336d0540fcd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73da7551c6424bfd8eaea8d31041aa84",
            "placeholder": "​",
            "style": "IPY_MODEL_3c83a29ec3f94d019bb137f215b87d5c",
            "value": " 349/349 [00:00&lt;00:00, 26.1kB/s]"
          }
        },
        "e33b135c9d0e426c9bb5d8935b67493e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc19181841f4efbaaa01ae1b3d3567d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d14adc46da4f75994b4bd20bb8a440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343af3fa46b442aba6d569efe2b26460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc84c4704e24800808ddc94fe38411e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73da7551c6424bfd8eaea8d31041aa84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c83a29ec3f94d019bb137f215b87d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eecfe7a5a18d42db9f2ce212d2062f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcb4d06eda74913962fc0e06e4541c3",
              "IPY_MODEL_6eacafac22394cdf862334a27f917157",
              "IPY_MODEL_06febb2f316645ed8ff20c79a6861072"
            ],
            "layout": "IPY_MODEL_8b7ab76268af4ef7acb6d4b8d112e7df"
          }
        },
        "dfcb4d06eda74913962fc0e06e4541c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7459935e448a4bc983a51b93e82081a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c09d13946dbc47c088735edee2d4cd5a",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "6eacafac22394cdf862334a27f917157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a986c4e040f243e8a6edabfdf59dfcde",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a3a3ab485624bc89a50a2d74c828597",
            "value": 116
          }
        },
        "06febb2f316645ed8ff20c79a6861072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77db5dfaa74142ea8a3a3b30ed894f77",
            "placeholder": "​",
            "style": "IPY_MODEL_75bc22f7ec5b4cd2b230594a7f95b9e1",
            "value": " 116/116 [00:00&lt;00:00, 7.32kB/s]"
          }
        },
        "8b7ab76268af4ef7acb6d4b8d112e7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7459935e448a4bc983a51b93e82081a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09d13946dbc47c088735edee2d4cd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a986c4e040f243e8a6edabfdf59dfcde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a3a3ab485624bc89a50a2d74c828597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77db5dfaa74142ea8a3a3b30ed894f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bc22f7ec5b4cd2b230594a7f95b9e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f65e948a790d47ecac9557672620d615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89f73480267b403692a9e7fc5e4a3778",
              "IPY_MODEL_edefa65b8b1146be83b7801a87b72f28",
              "IPY_MODEL_37145f9f0f9942eb8eec38b4ba73bd5a"
            ],
            "layout": "IPY_MODEL_8b12dc0501e043cfb2a6bf515d028259"
          }
        },
        "89f73480267b403692a9e7fc5e4a3778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a097caf00514dbcaa6b7d9579fb52c5",
            "placeholder": "​",
            "style": "IPY_MODEL_17c4ce0d6b1b4797ab748c2cd60563ce",
            "value": "README.md: 100%"
          }
        },
        "edefa65b8b1146be83b7801a87b72f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b905f1dd4406477683cd7642dc7dc8a8",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bc94c2e64b947e4b75759ba0d4c471a",
            "value": 10454
          }
        },
        "37145f9f0f9942eb8eec38b4ba73bd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f2f692a5d64cc49c94b4223aa47187",
            "placeholder": "​",
            "style": "IPY_MODEL_3be97350772947a5bbdb303126a73616",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "8b12dc0501e043cfb2a6bf515d028259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a097caf00514dbcaa6b7d9579fb52c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c4ce0d6b1b4797ab748c2cd60563ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b905f1dd4406477683cd7642dc7dc8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc94c2e64b947e4b75759ba0d4c471a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54f2f692a5d64cc49c94b4223aa47187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be97350772947a5bbdb303126a73616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e9d840769204ac68ff74302163abd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d3551971da94101a2465ec47cfb0131",
              "IPY_MODEL_007900d0367f4a26a5419b100d6d1429",
              "IPY_MODEL_4ff989de411b4e57b201745008a80500"
            ],
            "layout": "IPY_MODEL_605816660f6a4972829795ac22a4ca53"
          }
        },
        "3d3551971da94101a2465ec47cfb0131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_017ea207b1e8405795a1b5e2b7d1bb69",
            "placeholder": "​",
            "style": "IPY_MODEL_92707f8a1c284664b7780cc91ac16e9d",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "007900d0367f4a26a5419b100d6d1429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c900393bca46729699572ab0add119",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07f850d623b646329232f17e2c3e76cb",
            "value": 53
          }
        },
        "4ff989de411b4e57b201745008a80500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_374d60eec80a490eb556dc9808599cce",
            "placeholder": "​",
            "style": "IPY_MODEL_54f803bbdc464f18969b137c4a0561b2",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.22kB/s]"
          }
        },
        "605816660f6a4972829795ac22a4ca53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "017ea207b1e8405795a1b5e2b7d1bb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92707f8a1c284664b7780cc91ac16e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c900393bca46729699572ab0add119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f850d623b646329232f17e2c3e76cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "374d60eec80a490eb556dc9808599cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f803bbdc464f18969b137c4a0561b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "123521b0515346039420b76b55c53860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f5f2f1fd91042339479e33cbab0b235",
              "IPY_MODEL_b8dd95d2b8174014ae26d17a41395271",
              "IPY_MODEL_0a82e318a5b24ee68077565792a2362d"
            ],
            "layout": "IPY_MODEL_3eb7eaafa4d44d9d870d8bf56e3a006b"
          }
        },
        "9f5f2f1fd91042339479e33cbab0b235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc6188dd268460083a1ded6f474687a",
            "placeholder": "​",
            "style": "IPY_MODEL_a0e74b5c74a54cddbb21e3ad17c617ac",
            "value": "config.json: 100%"
          }
        },
        "b8dd95d2b8174014ae26d17a41395271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83511826369c4116b1c9a7a439816225",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_634dc12b19dd4c158b4da8d81ddbe4d9",
            "value": 612
          }
        },
        "0a82e318a5b24ee68077565792a2362d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56bef8e0e75842c4be5ec56e4d43c35f",
            "placeholder": "​",
            "style": "IPY_MODEL_4244a1d3b3074f95b614280bc0d9d168",
            "value": " 612/612 [00:00&lt;00:00, 58.6kB/s]"
          }
        },
        "3eb7eaafa4d44d9d870d8bf56e3a006b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc6188dd268460083a1ded6f474687a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e74b5c74a54cddbb21e3ad17c617ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83511826369c4116b1c9a7a439816225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634dc12b19dd4c158b4da8d81ddbe4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56bef8e0e75842c4be5ec56e4d43c35f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4244a1d3b3074f95b614280bc0d9d168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9397a79f69bb4b8095df9fbcde7d28bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3ff7b2530664f3a9a25534b01015c2a",
              "IPY_MODEL_3d3c4e45a64b43728b46e9ee071fc4d5",
              "IPY_MODEL_1a8475b8e0e044bf95a53ad0d85b4c19"
            ],
            "layout": "IPY_MODEL_8ecd721b30444c4695a0f4b1bda996c8"
          }
        },
        "a3ff7b2530664f3a9a25534b01015c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2230ca957eb046c485741be9a29baa36",
            "placeholder": "​",
            "style": "IPY_MODEL_8e14a3000cde48768160da742b8589cc",
            "value": "model.safetensors: 100%"
          }
        },
        "3d3c4e45a64b43728b46e9ee071fc4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1fa872c2d334621920bb2609e9ebb88",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6497ce9a11244278a478258961554988",
            "value": 90868376
          }
        },
        "1a8475b8e0e044bf95a53ad0d85b4c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb44e06b3034efcb5c10f86bb83453c",
            "placeholder": "​",
            "style": "IPY_MODEL_5309c45580b34cbe9168480bc13eab3d",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 175MB/s]"
          }
        },
        "8ecd721b30444c4695a0f4b1bda996c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2230ca957eb046c485741be9a29baa36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e14a3000cde48768160da742b8589cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1fa872c2d334621920bb2609e9ebb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6497ce9a11244278a478258961554988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bb44e06b3034efcb5c10f86bb83453c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5309c45580b34cbe9168480bc13eab3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3eede86757645b397eebbd5ee4695dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb49423791e34c05b5cfba8b0a652254",
              "IPY_MODEL_9fe528296cec4b25a7ec90206e0c2e01",
              "IPY_MODEL_1335ac47d67840e1b6b827aa1dbd8985"
            ],
            "layout": "IPY_MODEL_60bcd320378843f39f1bb4a3a1ffa28b"
          }
        },
        "fb49423791e34c05b5cfba8b0a652254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49eda891b19485ea372cb9ac0ba8f47",
            "placeholder": "​",
            "style": "IPY_MODEL_1ae6d40927544990a4064b0c14a454cd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9fe528296cec4b25a7ec90206e0c2e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95585e8d4b2e43eaa481e43102a302d1",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f566a10837b14fe981f4a64afe03e4d1",
            "value": 350
          }
        },
        "1335ac47d67840e1b6b827aa1dbd8985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc39b128cd544c69b327e78eabe86420",
            "placeholder": "​",
            "style": "IPY_MODEL_b88b978c16374d67a68efbfc48707275",
            "value": " 350/350 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "60bcd320378843f39f1bb4a3a1ffa28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49eda891b19485ea372cb9ac0ba8f47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ae6d40927544990a4064b0c14a454cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95585e8d4b2e43eaa481e43102a302d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f566a10837b14fe981f4a64afe03e4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc39b128cd544c69b327e78eabe86420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88b978c16374d67a68efbfc48707275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dda89d070519437a849f6220f77feade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34771befd49548399868056129e4de04",
              "IPY_MODEL_47803afb6a8041ce97e427d2895c2296",
              "IPY_MODEL_233c867b81c9403ca44809fc3c1165e2"
            ],
            "layout": "IPY_MODEL_d3b9f277767e4960899e2032e3733ccf"
          }
        },
        "34771befd49548399868056129e4de04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db1051c9dc8496d91908bccf127f549",
            "placeholder": "​",
            "style": "IPY_MODEL_3ecf418cc24342f9a3a980edf8c32eaa",
            "value": "vocab.txt: 100%"
          }
        },
        "47803afb6a8041ce97e427d2895c2296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6fa6f925f17474f956dc22b6ab55ce5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f23c52f16de4fb998e682b01c60572a",
            "value": 231508
          }
        },
        "233c867b81c9403ca44809fc3c1165e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c608a129ff54977b7abc5a1d2e342bc",
            "placeholder": "​",
            "style": "IPY_MODEL_789bd27a98df4791a860b82bbb1ade53",
            "value": " 232k/232k [00:00&lt;00:00, 1.78MB/s]"
          }
        },
        "d3b9f277767e4960899e2032e3733ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db1051c9dc8496d91908bccf127f549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecf418cc24342f9a3a980edf8c32eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6fa6f925f17474f956dc22b6ab55ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f23c52f16de4fb998e682b01c60572a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c608a129ff54977b7abc5a1d2e342bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789bd27a98df4791a860b82bbb1ade53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5078d704cdd04ec4b1605ac7791b5971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c36a89ae5b0b4e31995de0d2009971e4",
              "IPY_MODEL_9901b5319e284b4694a0451eaca6254b",
              "IPY_MODEL_ff81fb1f991a4f84af0d30c4e2a02f9f"
            ],
            "layout": "IPY_MODEL_4bd4f32877ac47a281bbf13c7810b992"
          }
        },
        "c36a89ae5b0b4e31995de0d2009971e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c625896d787b404f9c021d7086ed888f",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab0d3c03a964d07bfe165efa31b5142",
            "value": "tokenizer.json: 100%"
          }
        },
        "9901b5319e284b4694a0451eaca6254b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49f6e7665d04d7d8b3c2b5f8d2b3e10",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b391a14a59f8444f97fd6f1b00ae98f6",
            "value": 466247
          }
        },
        "ff81fb1f991a4f84af0d30c4e2a02f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_332cac79136c4165864e14735b86e4c1",
            "placeholder": "​",
            "style": "IPY_MODEL_cb439590c6b94e8eb2f56520f943ce5d",
            "value": " 466k/466k [00:00&lt;00:00, 3.27MB/s]"
          }
        },
        "4bd4f32877ac47a281bbf13c7810b992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c625896d787b404f9c021d7086ed888f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab0d3c03a964d07bfe165efa31b5142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d49f6e7665d04d7d8b3c2b5f8d2b3e10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b391a14a59f8444f97fd6f1b00ae98f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "332cac79136c4165864e14735b86e4c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb439590c6b94e8eb2f56520f943ce5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d1178fa583d4a45b06aab4ca07f7c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1985a25a8da4dca931cf8af78459585",
              "IPY_MODEL_2f2a620d13ed48c0ab42064946b31350",
              "IPY_MODEL_a1d563faf0104c038dfd33f0f826b696"
            ],
            "layout": "IPY_MODEL_7f57ee095a004293a84cb5fd0bb95628"
          }
        },
        "d1985a25a8da4dca931cf8af78459585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_665be036c2c4451e96dc7b1899c1c184",
            "placeholder": "​",
            "style": "IPY_MODEL_7efdf40089324b98b339b27d4ff27661",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "2f2a620d13ed48c0ab42064946b31350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3346582eaec44958cc4a6a7321aabc0",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63e6c1bf7a8d44b786b6f82fb77c2228",
            "value": 112
          }
        },
        "a1d563faf0104c038dfd33f0f826b696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8795590b17a84091a8b572dc201ab8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_76a3244073734b3c92989179341ac867",
            "value": " 112/112 [00:00&lt;00:00, 9.58kB/s]"
          }
        },
        "7f57ee095a004293a84cb5fd0bb95628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665be036c2c4451e96dc7b1899c1c184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7efdf40089324b98b339b27d4ff27661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3346582eaec44958cc4a6a7321aabc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e6c1bf7a8d44b786b6f82fb77c2228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8795590b17a84091a8b572dc201ab8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a3244073734b3c92989179341ac867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc716d25e9c455eaca5d2644ba91ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90e75ef764164eb8bd3d1e761d60eb82",
              "IPY_MODEL_16f6cd63e0e5467ea3f81d95477f14e2",
              "IPY_MODEL_bda01d79e9e94042a4103d0817d38818"
            ],
            "layout": "IPY_MODEL_6741953a7a35442abddb468e3ee3f53a"
          }
        },
        "90e75ef764164eb8bd3d1e761d60eb82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a382f798e08948049ae1953f4cf7e2cf",
            "placeholder": "​",
            "style": "IPY_MODEL_61182b1df7be4d4588a56d2c4d6c1e62",
            "value": "config.json: 100%"
          }
        },
        "16f6cd63e0e5467ea3f81d95477f14e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845b4611b51e4af1821914569d01e66f",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_186ecf9ed10f499a8ae514003f788e97",
            "value": 190
          }
        },
        "bda01d79e9e94042a4103d0817d38818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62f5907684094693ac4cfbfd3b69738b",
            "placeholder": "​",
            "style": "IPY_MODEL_de2c7ac7465d4085aff76671a131d50a",
            "value": " 190/190 [00:00&lt;00:00, 20.2kB/s]"
          }
        },
        "6741953a7a35442abddb468e3ee3f53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a382f798e08948049ae1953f4cf7e2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61182b1df7be4d4588a56d2c4d6c1e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "845b4611b51e4af1821914569d01e66f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "186ecf9ed10f499a8ae514003f788e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62f5907684094693ac4cfbfd3b69738b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2c7ac7465d4085aff76671a131d50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f751b8cf19f4efd973fc9fe02094a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f17ccb1071414ea689b5809839bc2b1d",
              "IPY_MODEL_040fdb78c7e642fca9685ee10601a678",
              "IPY_MODEL_3c7a33174d2b4605b7bc375eed4d784d"
            ],
            "layout": "IPY_MODEL_c8caea775e06441eaeb3534b754bd42e"
          }
        },
        "f17ccb1071414ea689b5809839bc2b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edcb10a86a5146cda0ee9cc5e84892e6",
            "placeholder": "​",
            "style": "IPY_MODEL_6776f81882e94af7907bb9ef585bc0cc",
            "value": "Batches: 100%"
          }
        },
        "040fdb78c7e642fca9685ee10601a678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecbca424ca244c7687d8ec247178d09b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0440cacd809446899e50dff6d910257",
            "value": 3
          }
        },
        "3c7a33174d2b4605b7bc375eed4d784d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d8af5872074e67acae6553d3e8be28",
            "placeholder": "​",
            "style": "IPY_MODEL_010144c3df2b42ce8dafa7af1afb1e59",
            "value": " 3/3 [00:00&lt;00:00,  5.00it/s]"
          }
        },
        "c8caea775e06441eaeb3534b754bd42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edcb10a86a5146cda0ee9cc5e84892e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6776f81882e94af7907bb9ef585bc0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecbca424ca244c7687d8ec247178d09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0440cacd809446899e50dff6d910257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1d8af5872074e67acae6553d3e8be28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "010144c3df2b42ce8dafa7af1afb1e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahriar-faghani/SIIM_2025_AgenticAI_workshop/blob/main/Multi_Agent_Large_Language_Models_SIIM2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multi-Agent Large Language Models in Neuroradiology.\n",
        "##SIIM 2025\n",
        "\n",
        "Authors:\n",
        "- **Shahriar Faghani**, MD\n",
        "- **Pouria Rouzrokh**, MD, MPH, MHPE\n",
        "- **Mana Moassefi**, MD\n",
        "\n",
        "Welcome to this workshop! Here, we will learn together how multi-agent LLM-based systems can enhance radiology workflows."
      ],
      "metadata": {
        "id": "ztoUdmIZuLYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Setup and Installation\n",
        "This first section handles the necessary setup for our Colab environment. We'll update system packages, install required Python libraries, import them, and configure access to Google Drive and API keys.\n",
        "\n",
        "### System Updates & Dependencies\n",
        "\n",
        "First, let's update the system package list and install ffmpeg. This is a command-line tool required by the openai-whisper library for processing audio files."
      ],
      "metadata": {
        "id": "xCKThRsvtTuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Update package list and install ffmpeg\n",
        "!apt-get update -y && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6z0aslstXbs",
        "outputId": "9e278be5-ea27-472b-e77c-76b7174afd77",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,944 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,725 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Fetched 30.6 MB in 3s (10.8 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 89 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Install Python Packages\n",
        "\n",
        "Next, we install all the Python libraries needed for this project using pip. We use the --quiet flag to reduce installation noise.\n",
        "smolagents[transformers]: The core framework for building multi-agent systems, including support for transformer-based models.\n",
        "gradio: To create the interactive web UI for transcription and analysis.\n",
        "openai-whisper: For accurate speech-to-text transcription.\n",
        "python-dotenv: To load API keys securely from a .env file.\n",
        "groq: The client library to interact with the fast Groq LLM API (used for entity extraction).\n",
        "openai: Often useful for various LLM interactions or helper functions.\n",
        "requests, beautifulsoup4: For fetching and parsing web content (specifically Radiopaedia).\n",
        "sentence-transformers: To generate text embeddings for our local PDF search (RAG).\n",
        "faiss-cpu: A library for efficient similarity search, used to index the PDF embeddings.\n",
        "PyPDF2: To extract text content from PDF files.\n",
        "huggingface_hub: For logging into Hugging Face and using models/tools from the Hub.\n",
        "torch: The underlying deep learning framework needed by Whisper and SentenceTransformers."
      ],
      "metadata": {
        "id": "UMNTUFUntsPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Install required Python packages\n",
        "!pip install --quiet \\\n",
        "    smolagents[transformers] \\\n",
        "    gradio \\\n",
        "    openai-whisper \\\n",
        "    python-dotenv \\\n",
        "    groq \\\n",
        "    openai \\\n",
        "    requests \\\n",
        "    beautifulsoup4 \\\n",
        "    sentence-transformers \\\n",
        "    faiss-cpu \\\n",
        "    PyPDF2 \\\n",
        "    huggingface_hub \\\n",
        "    torch \\\n",
        "    duckduckgo-search"
      ],
      "metadata": {
        "id": "mp2520kVttV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cab0c7b-4d78-4323-adb5-a6a681d8cfeb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Import Libraries\n",
        "\n",
        "Now we import all the necessary modules and classes into our Python environment."
      ],
      "metadata": {
        "id": "spNsaZNEvGBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import time\n",
        "import json # For handling structured data between agents\n",
        "from pathlib import Path\n",
        "import shutil # For cleaning /tmp if needed\n",
        "\n",
        "# Web and API interaction\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from groq import Groq\n",
        "from huggingface_hub import login, HfFolder\n",
        "\n",
        "# Deep Learning and NLP\n",
        "import torch\n",
        "import whisper\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# PDF Processing\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# UI and Environment\n",
        "import getpass\n",
        "import gradio as gr\n",
        "from google.colab import drive, files # For Drive mounting\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# SmolAgents core components\n",
        "from smolagents import (\n",
        "    Tool, # Base class for tools (alternative definition method)\n",
        "    tool, # Decorator for function-based tools (preferred)\n",
        "    CodeAgent,\n",
        "    InferenceClientModel, # Connects to HF Inference API and partners\n",
        ")"
      ],
      "metadata": {
        "id": "pfla5G9xt0TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Mount Google Drive and Environment Setup\n",
        "To access API keys securely and load reference PDF documents, we need to connect this Colab notebook to your Google Drive.\n",
        "\n",
        "**Action Required:**\n",
        "\n",
        "1. Run the next cell. It will prompt you to authorize access to your Google Drive. Follow the link, sign in, copy the authorization code, and paste it back into the Colab input field.\n",
        "2. In your Google Drive's root folder (My Drive), create a new folder named RadiologyMultiAgentColab.\n",
        "3. Inside RadiologyMultiAgentColab, create a file named api.env.\n",
        "4. Edit the api.env file and add your API keys like this (replace placeholders with your actual keys):\n",
        "```python\n",
        "HF_TOKEN=hf_YourHuggingFaceTokenHere\n",
        "GROQ_API_KEY=gsk_YourGroqApiKeyHere\n",
        "```\n",
        "5. Inside RadiologyMultiAgentColab, create another folder named SharedRadiologyPDFs.\n",
        "6. Upload your internal reference PDF documents into the SharedRadiologyPDFs folder (For testing, you might place a sample PDF like Neuroradiology_Core_Reference.pdf there).\n",
        "\n",
        "The following code will attempt to mount your drive and load the api.env file."
      ],
      "metadata": {
        "id": "f0GvSrQtwDC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove sample_data folder\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "# Mount Google Drive\n",
        "MOUNT_GOOGLE_DRIVE = True #@param {type:\"boolean\"}\n",
        "USE_GETPASS = True #@param {type:\"boolean\"}\n",
        "\n",
        "if MOUNT_GOOGLE_DRIVE:\n",
        "  try:\n",
        "      drive.mount('/content/drive')\n",
        "      print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "      # Define base path for project files in Drive\n",
        "      DRIVE_PROJECT_PATH = Path('/content/drive/MyDrive/RadiologyMultiAgentColab')\n",
        "\n",
        "      # Ensure the project directory exists\n",
        "      #DRIVE_PROJECT_PATH.mkdir(parents=True, exist_ok=True)\n",
        "      Path('/content/drive/MyDrive/RadiologyMultiAgentColab/SharedRadiologyPDFs').mkdir(parents=True, exist_ok=True)\n",
        "      print(f\"Project path set to: {DRIVE_PROJECT_PATH}\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    MOUNT_GOOGLE_DRIVE = False\n",
        "\n",
        "if not MOUNT_GOOGLE_DRIVE:\n",
        "    print(\"Not running in Google Colab environment. Google Drive not mounted.\")\n",
        "    print(\"Please ensure your api.env file and PDF references are accessible locally.\")\n",
        "    DRIVE_PROJECT_PATH = Path('.')\n",
        "\n",
        "# --- Load Environment Variables ---\n",
        "env_path = DRIVE_PROJECT_PATH / 'api.env'\n",
        "if env_path.exists():\n",
        "    load_dotenv(dotenv_path=env_path)\n",
        "    print(f\".env file found and loaded from the path: {env_path}.\")\n",
        "else:\n",
        "    print(f\"Warning: .env file not found at {env_path}. Falling back to getpass.\")\n",
        "    if USE_GETPASS:\n",
        "      try:\n",
        "        # Prompt for and save Hugging Face API token\n",
        "        hf_token = getpass.getpass(\"Enter your Hugging Face API token: \")\n",
        "        os.environ[\"HF_TOKEN\"] = hf_token\n",
        "        print(\"Hugging Face API token saved.\")\n",
        "        # Prompt for and save Groq API key\n",
        "        groq_key = getpass.getpass(\"Enter your Groq API key: \")\n",
        "        os.environ[\"GROQ_API_KEY\"] = groq_key\n",
        "        print(\"Groq API key saved.\")\n",
        "      except Exception as e:\n",
        "          print(f\"Error accessing Colab secrets: {e}\")\n",
        "    else:\n",
        "      print(f\"Please make sure the '.env' file is present and accessible.\")"
      ],
      "metadata": {
        "id": "dIISQ8w9vKMm",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef5941b-d584-4e2c-a0e9-5201f1e6f3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Project path set to: /content/drive/MyDrive/RadiologyMultiAgentColab\n",
            "Warning: .env file not found at /content/drive/MyDrive/RadiologyMultiAgentColab/api.env. Falling back to getpass.\n",
            "Enter your Hugging Face API token: ··········\n",
            "Hugging Face API token saved.\n",
            "Enter your Groq API key: ··········\n",
            "Groq API key saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 API Key Verification and Login\n",
        "Let's verify that the API keys were loaded correctly and log in to the Hugging Face Hub. We also initialize the Groq client."
      ],
      "metadata": {
        "id": "WG0gqzAg0Dbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- API Key Verification and Login ---\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "groq_client = None # Initialize client variable\n",
        "\n",
        "if not HF_TOKEN:\n",
        "    print(\"⚠️ Hugging Face Token (HF_TOKEN) not found. Analysis requiring Hugging Face models will fail.\")\n",
        "    print(\"   Please add it to your .env file or Colab secrets.\")\n",
        "else:\n",
        "    try:\n",
        "        login(token=HF_TOKEN, add_to_git_credential=False) # Avoid git credential helper issues in Colab\n",
        "        print(\"✅ Successfully logged into Hugging Face Hub.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error logging into Hugging Face Hub: {e}\")\n",
        "        print(\"   Please ensure your HF_TOKEN is valid.\")\n",
        "\n",
        "if not GROQ_API_KEY:\n",
        "    print(\"⚠️ Groq API Key (GROQ_API_KEY) not found. Entity extraction will fail.\")\n",
        "    print(\"   Please add it to your .env file or Colab secrets.\")\n",
        "else:\n",
        "    try:\n",
        "        groq_client = Groq(api_key=GROQ_API_KEY)\n",
        "        # Test Groq connection by listing models\n",
        "        models = groq_client.models.list()\n",
        "        print(f\"✅ Successfully connected to Groq API. Available models (first few): {[m.id for m in models.data[:3]]}...\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error connecting to Groq API: {e}\")\n",
        "        print(\"   Please ensure your GROQ_API_KEY is valid.\")\n",
        "        groq_client = None # Ensure client is None if connection failed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpLkT_pKyojt",
        "outputId": "7a28315c-66f9-4dc2-b2f7-bb8529c627a7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully logged into Hugging Face Hub.\n",
            "✅ Successfully connected to Groq API. Available models (first few): ['compound-beta-mini', 'playai-tts-arabic', 'llama-3.1-8b-instant']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5 PDF Reference Path Setup\n",
        "\n",
        "We define the path to the folder containing your local PDF references and check if it exists and contains PDF files."
      ],
      "metadata": {
        "id": "ZH46KEnZ0fu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- PDF Reference Path ---\n",
        "PDF_FOLDER_PATH = DRIVE_PROJECT_PATH / 'SharedRadiologyPDFs'\n",
        "\n",
        "if PDF_FOLDER_PATH.exists() and PDF_FOLDER_PATH.is_dir():\n",
        "    print(f\"✅ PDF reference folder found at: {PDF_FOLDER_PATH}\")\n",
        "    pdf_files = list(PDF_FOLDER_PATH.glob(\"*.pdf\"))\n",
        "    if pdf_files:\n",
        "        print(f\"   Found {len(pdf_files)} PDF file(s):\")\n",
        "        for pdf_file in pdf_files[:5]: # Print first 5\n",
        "             print(f\"   - {pdf_file.name}\")\n",
        "        if len(pdf_files) > 5:\n",
        "            print(\"   ...\")\n",
        "    else:\n",
        "        print(f\"⚠️ Warning: The folder {PDF_FOLDER_PATH} exists, but no PDF files were found inside.\")\n",
        "else:\n",
        "    print(f\"⚠️ Warning: PDF reference folder not found or is not a directory at {PDF_FOLDER_PATH}\")\n",
        "    print(\"   Please ensure you created the 'SharedRadiologyPDFs' folder inside 'RadiologyMultiAgentColab' and uploaded PDFs.\")\n",
        "    pdf_files = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kg50euq0g0Y",
        "outputId": "27e9e9a0-7d71-472c-839e-e1f763f2c4be",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF reference folder found at: /content/drive/MyDrive/RadiologyMultiAgentColab/SharedRadiologyPDFs\n",
            "   Found 3 PDF file(s):\n",
            "   - AD-M2400 ARIA in the ED infographic.pdf\n",
            "   - ARIA_differential_diagnosis.pdf\n",
            "   - jksr-86-17-s001.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.6 Check GPU Availability\n",
        "Machine learning tasks like transcription and embedding generation run much faster on a GPU. Let's check if one is available in this Colab session. (Go to Runtime -> Change runtime type -> Hardware accelerator -> GPU if needed)."
      ],
      "metadata": {
        "id": "3Etq4xBQ0nrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Check for GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🤖 Using device: {device.upper()}\")\n",
        "if device == \"cpu\":\n",
        "    print(\"   Note: Operations like transcription and embedding will be slower on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhdgELSv0lBM",
        "outputId": "818b6672-e4e0-46e6-fcc6-0865a5294a1e",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Using device: CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.7 Clean Temporary Files\n",
        "\n",
        "Sometimes, Colab's temporary directory (/tmp) can fill up. Uncomment and run the following cell if you encounter disk space errors later."
      ],
      "metadata": {
        "id": "VHfXwMpe0wza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Optional: Clean Temporary Files ---\n",
        "\n",
        "# tmp_path = Path('/tmp')\n",
        "# if tmp_path.exists():\n",
        "#     print(\"Cleaning /tmp/ directory...\")\n",
        "#     cleaned_count = 0\n",
        "#     error_count = 0\n",
        "#     for item in tmp_path.iterdir():\n",
        "#         try:\n",
        "#             if item.is_file() or item.is_symlink():\n",
        "#                 item.unlink()\n",
        "#                 cleaned_count += 1\n",
        "#             elif item.is_dir():\n",
        "#                 shutil.rmtree(item)\n",
        "#                 cleaned_count += 1\n",
        "#         except Exception as e:\n",
        "#             # print(f\"Could not remove {item}: {e}\") # Can be noisy\n",
        "#             error_count += 1\n",
        "#     print(f\"/tmp/ directory cleaned. Removed {cleaned_count} items. Encountered {error_count} errors.\")"
      ],
      "metadata": {
        "id": "wEbeuLHL0qkF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Transcription Interface with Whisper + Gradio\n",
        "In this section, we'll set up the speech-to-text transcription functionality. We'll load the OpenAI Whisper model and create a simple Gradio interface that allows users to:\n",
        "\n",
        "- See a sample brain MRI image for context.\n",
        "Record a short radiology report using their microphone.\n",
        "- Get the transcribed text output.\n",
        "\n",
        "This initial interface will help us test the transcription part before integrating it into the full multi-agent workflow.\n",
        "### Load Whisper Model\n",
        "We'll load a pre-trained Whisper model, that is a well-known speech to text model. Whisper comes in various sizes (e.g., tiny, base, small, medium, large). Larger models are generally more accurate but slower and require more resources. Smaller models can run on regular devices (e.g., Macbooks and even some smart mobile phones).\n",
        "\n",
        "For this educational notebook, base.en (English-only base model) is a good balance. We ensure the model is loaded only once to save resources."
      ],
      "metadata": {
        "id": "o8Vv6Fdmvoou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Load Whisper Model\n",
        "# Ensure model is loaded only once using a global-like check\n",
        "\n",
        "try:\n",
        "  whisper_model\n",
        "except NameError:\n",
        "  whisper_model = None\n",
        "\n",
        "# You can choose different model sizes: \"tiny.en\", \"base.en\", \"small.en\", \"medium.en\"\n",
        "# \".en\" models are English-only and typically faster/smaller than multilingual ones.\n",
        "whisper_model_size = \"base.en\"\n",
        "\n",
        "if 'whisper_model' not in globals() or whisper_model is None:\n",
        "    try:\n",
        "        print(\"Loading Whisper model (this may take a moment)...\")\n",
        "        whisper_model = whisper.load_model(whisper_model_size, device=device)\n",
        "        print(f\"✅ Whisper model '{whisper_model_size}' loaded successfully on {device.upper()}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading Whisper model: {e}\")\n",
        "        print(\"   Transcription functionality will not work. Please check your setup and GPU (if selected).\")\n",
        "        whisper_model = None\n",
        "else:\n",
        "    print(f\"✅ Whisper model ('{whisper_model_size}') already loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rBAJ6RmvZwi",
        "outputId": "a634e7e8-a09a-44e5-b68a-cf9d0d0dafc3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model (this may take a moment)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:04<00:00, 32.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Whisper model 'base.en' loaded successfully on CUDA.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Define Transcription Function\n",
        "This Python function takes the filepath of an audio recording (as provided by Gradio) and uses the loaded Whisper model to convert the speech into text. It includes basic error handling.\n"
      ],
      "metadata": {
        "id": "03hDeOI7w6Li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def transcribe_audio(audio_filepath: str | None) -> str:\n",
        "    \"\"\"\n",
        "    Transcribes the given audio file using the pre-loaded Whisper model.\n",
        "\n",
        "    Args:\n",
        "        audio_filepath: Path to the audio file, or None if no file is provided.\n",
        "\n",
        "    Returns:\n",
        "        The transcribed text, or an error/informational message.\n",
        "    \"\"\"\n",
        "    if whisper_model is None:\n",
        "        return \"Error: Whisper model is not loaded. Cannot transcribe.\"\n",
        "    if not audio_filepath: # Gradio might pass None if no audio is recorded\n",
        "        return \"No audio recorded. Please use the microphone to record your report.\"\n",
        "\n",
        "    print(f\"Transcribing audio file: {audio_filepath}...\")\n",
        "    try:\n",
        "        # The 'language' parameter can be useful for multilingual models.\n",
        "        # For \".en\" models, it's less critical but doesn't hurt.\n",
        "        result = whisper_model.transcribe(audio_filepath, language='en', fp16=torch.cuda.is_available())\n",
        "        transcription = result['text']\n",
        "        print(\"Transcription complete.\")\n",
        "        return transcription.strip() if transcription else \"Transcription result was empty.\"\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during transcription: {e}\")\n",
        "        return f\"Error during transcription: {e}\""
      ],
      "metadata": {
        "id": "oJEmuI0EwvyB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Simple Gradio Interface for Transcription\n",
        "Now, we'll create a basic Gradio interface. It will display:\n",
        "- A title and brief instructions.\n",
        "- A sample brain MRI image to provide context for the dictation.\n",
        "- An audio input component that allows recording from the microphone.\n",
        "- A button to trigger the transcription.\n",
        "- A textbox to display the transcription result.\n",
        "\n",
        "This interface will be launched for testing. Later, we'll build a more advanced, integrated GUI for our multiagent workflow!"
      ],
      "metadata": {
        "id": "XQ5BH_UyxHwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Simple Gradio Interface for Transcription\n",
        "\n",
        "# --- Brain MRI Image ---\n",
        "# You can replace this URL with a direct link to any publicly accessible image,\n",
        "# or upload an image to your Colab session and use its local path.\n",
        "# For demonstration, we use a Wikimedia Commons link.\n",
        "brain_image_url = 'https://radiologyassistant.nl/assets/brain-ischemia-vascular-territories/a509797855a416_PCA-infarct2.jpg'\n",
        "brain_image_caption = \"Sample Brain CT (Axial non-contrast)\"\n",
        "\n",
        "print(\"Setting up basic Gradio transcription interface...\")\n",
        "\n",
        "with gr.Blocks(css=\"footer {display: none !important}\") as basic_transcription_interface:\n",
        "    gr.Markdown(\"# Step 1: Transcribe Your Radiology Report\")\n",
        "    gr.Markdown(\n",
        "        \"Focus on the image below (or imagine a case). \"\n",
        "        \"Record a short dictation (3-4 sentences) using your microphone, \"\n",
        "        \"then click 'Transcribe Audio' to see the text.\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        gr.Image(value=brain_image_url, label=brain_image_caption, height=350, width=350, elem_id=\"sample-mri-image\")\n",
        "        with gr.Column(scale=2): # Give more space to controls\n",
        "            audio_input = gr.Audio(\n",
        "                sources=[\"microphone\"],\n",
        "                type=\"filepath\", # Whisper needs a filepath\n",
        "                label=\"Record Your Report Dictation Here:\"\n",
        "            )\n",
        "            transcribe_button = gr.Button(\"🎤 Transcribe Audio\", variant=\"primary\")\n",
        "\n",
        "    transcription_output = gr.Textbox(\n",
        "        label=\"📝 Transcription Result:\",\n",
        "        lines=5,\n",
        "        placeholder=\"Your transcribed report will appear here...\"\n",
        "    )\n",
        "\n",
        "    # Connect button click to the transcription function\n",
        "    transcribe_button.click(\n",
        "        fn=transcribe_audio,\n",
        "        inputs=audio_input,\n",
        "        outputs=transcription_output\n",
        "    )\n",
        "\n",
        "# --- Launch the basic interface for testing ---\n",
        "# Note: We will comment this out or remove it when we build the final advanced GUI,\n",
        "# as launching multiple Gradio apps in one notebook can sometimes be problematic.\n",
        "# For now, it's useful for isolated testing of transcription.\n",
        "\n",
        "# To run this interface, uncomment the line below.\n",
        "basic_transcription_interface.launch(share=True, debug=True)\n",
        "print(\"Basic transcription interface launched. You can test recording and transcription now.\")\n",
        "print(\"After testing, you might want to interrupt/stop this cell before proceeding to avoid issues with the final GUI.\")"
      ],
      "metadata": {
        "id": "yQ1wLB3TxHJu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "7c553285-52bc-46bb-ce3b-5884d2ec5a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up basic Gradio transcription interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://15565d806211634db5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://15565d806211634db5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing audio file: /tmp/gradio/4d768cd1abeb39db0ab3034ec1e6759f48d6530fe78523643644b431e76e4b3b/audio.wav...\n",
            "Transcription complete.\n",
            "Transcribing audio file: /tmp/gradio/4d768cd1abeb39db0ab3034ec1e6759f48d6530fe78523643644b431e76e4b3b/audio.wav...\n",
            "Transcription complete.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://15565d806211634db5.gradio.live\n",
            "Basic transcription interface launched. You can test recording and transcription now.\n",
            "After testing, you might want to interrupt/stop this cell before proceeding to avoid issues with the final GUI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Tool Definitions\n",
        "In the SmolAgents framework, \"tools\" are specialized functions that our AI agents can utilize to perform specific actions or interact with external data sources. The Large Language Model (LLM) that powers each agent intelligently decides which tool to use based on its current task and the descriptive information provided for each available tool.\n",
        "\n",
        "We will define three main tools for our radiology workflow:\n",
        "\n",
        "1. **Radiopaedia Content Extraction Tool** (*radiopaedia_content_extraction_tool*): This tool is designed to fetch the main textual content from a specific Radiopaedia.org article, given its direct URL. The URL itself will be identified by the RadiopaediaExpertAgent using a general web search.\n",
        "\n",
        "2. **Internal PDF RAG Query Tool** (*query_internal_references_tool*): This tool enables searching our curated library of local PDF documents (e.g., textbooks, guidelines). When given a query, typically an imaging finding, it retrieves the most relevant text chunks from these PDFs. Its output is a structured JSON string, providing not just the text but also metadata like the source PDF and a unique global_chunk_index for each chunk. This index is vital for contextual expansion.\n",
        "\n",
        "3. **Retrieve Neighboring Chunks Tool** (*retrieve_neighboring_chunks_tool*): This new tool works in conjunction with the RAG query tool. Given the global_chunk_index of a chunk retrieved by the RAG tool, it fetches a specified number of text chunks immediately preceding and succeeding it from the same source PDF document. This allows an agent to gain broader context around an initially identified relevant piece of information.\n",
        "\n",
        "4. **Web Search Tool** (*DuckDuckGoSearchTool*): A general-purpose web search tool (using DuckDuckGo) provided by SmolAgents, which our RadiopaediaExpertAgent will use to find relevant article URLs.\n",
        "\n",
        "We'll use the @tool decorator from SmolAgents, which is a convenient way to wrap Python functions and make them usable by agents. It automatically infers the tool's name, inputs, and output types from the function signature and docstring."
      ],
      "metadata": {
        "id": "tPPdqfMwy_QV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Radiopaedia Content Extraction Tool\n",
        "\n",
        "Defining this tool is mostly straightforward as it does not need us to define any helper functions."
      ],
      "metadata": {
        "id": "pi3a2c394Lxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 3\n",
        "\n",
        "@tool\n",
        "def radiopaedia_content_extraction_tool(page_url: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches a specific Radiopaedia.org article page given its full URL and extracts\n",
        "    the main textual content. It aims to return a clean version of the article body.\n",
        "    The calling agent is responsible for summarizing this extracted content.\n",
        "\n",
        "    Args:\n",
        "        page_url (str): The full URL of the Radiopaedia article to process\n",
        "                        (e.g., \"https://radiopaedia.org/articles/stroke?lang=us\").\n",
        "\n",
        "    Returns:\n",
        "        str: A string containing the extracted and cleaned textual content of the article.\n",
        "             The content might be truncated by this tool if exceedingly long to ensure manageability.\n",
        "             If an error occurs (e.g., URL not found, content not extractable),\n",
        "             an error message string is returned (e.g., \"Error: Failed to fetch...\").\n",
        "    \"\"\"\n",
        "    print(f\"Radiopaedia Content Extractor: Attempting to fetch URL: {page_url}\")\n",
        "    # Validate that the URL is for a Radiopaedia article\n",
        "    if not page_url or not (page_url.startswith(\"http://radiopaedia.org/articles/\") or page_url.startswith(\"https://radiopaedia.org/articles/\")):\n",
        "        return \"Error: Invalid or non-Radiopaedia article URL provided. URL must start with 'http(s)://radiopaedia.org/articles/'.\"\n",
        "\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
        "        \"Accept-Language\": \"en-US,en;q=0.5\", # Prefer English content\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        resp = requests.get(page_url, headers=headers, timeout=25) # Timeout for the request\n",
        "        resp.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"   ❌ Timeout error fetching Radiopaedia URL: {page_url}\")\n",
        "        return f\"Error: Timeout occurred while attempting to fetch the Radiopaedia page: {page_url}\"\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"   ❌ HTTP error {e.response.status_code} fetching Radiopaedia URL {page_url}: {e}\")\n",
        "        return f\"Error: An HTTP error ({e.response.status_code}) occurred while fetching the Radiopaedia page: {page_url}.\"\n",
        "    except requests.exceptions.RequestException as e: # Catch other network-related errors\n",
        "        print(f\"   ❌ Network request error fetching Radiopaedia URL {page_url}: {e}\")\n",
        "        return f\"Error: A network connection error occurred while attempting to fetch the Radiopaedia page: {page_url}.\"\n",
        "\n",
        "    try:\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "        # Try to find the main article body using common class names on Radiopaedia\n",
        "        body = soup.find(\"div\", class_=\"article-body\")\n",
        "        if not body: # Fallback to another common class name\n",
        "            body = soup.find(\"div\", class_=\"body user-generated-content\")\n",
        "\n",
        "        if not body:\n",
        "            print(f\"   ❌ Could not find the main article content section at URL: {page_url}. The page structure may have changed or the URL might not be a standard article page.\")\n",
        "            return f\"Error: Could not find the main article content section at URL: {page_url}. The page structure might differ from expected.\"\n",
        "\n",
        "        # List of CSS selectors for elements to remove to clean up the content\n",
        "        unwanted_selectors = [\n",
        "            \"div.ad-banner-mobile\", \"div.ad-container\", \"aside.article-aside\", \"div.rb-quick-links\",\n",
        "            \"div.questions.expandable\", \"div.references.expandable\", \"div.reference_lists\",\n",
        "            \"div.incoming-links.expandable\", \"div.article-quiz-callout\", \"div#article-images-carousel\",\n",
        "            \"div.article-related-articles-callout\", \"div.article-social-sharing\",\n",
        "            \"div.article-licence\", \"div.article-segmentation-map\", \"div.article-metadata-row\",\n",
        "            \"figure\", \"figcaption\", # Remove image figures and captions\n",
        "            \"a.image-thumbnail\", \"script\", \"style\", \"nav\", \"footer\", \"header\", # Remove non-content elements\n",
        "            \"div.article-doi\", \"div.article-updated-at\", \"div.article-contributors\", \"div.article-case-links-title\",\n",
        "            \".article-images-header\", \".image-object-counter\", \".article-jump-to-top\", \".article-actions\"\n",
        "        ]\n",
        "        for selector in unwanted_selectors:\n",
        "            for unwanted_tag in body.select(selector):\n",
        "                unwanted_tag.decompose() # Remove the tag and all its children\n",
        "\n",
        "        # Extract text primarily from paragraphs and heading elements for better semantic structure\n",
        "        text_elements = body.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'li'])\n",
        "        content_parts = [elem.get_text(separator=\" \", strip=True) for elem in text_elements]\n",
        "\n",
        "        processed_text_parts = []\n",
        "        for part in content_parts:\n",
        "            if part: # Ensure part is not empty after stripping\n",
        "                # Add more spacing for headings or longer paragraphs for readability\n",
        "                if part.startswith(tuple(f'<h{i}>' for i in range(1,7))) or len(part) > 100 : # crude check for heading or paragraph\n",
        "                     processed_text_parts.append(part + \"\\n\\n\")\n",
        "                else: # for list items or shorter text, less spacing\n",
        "                     processed_text_parts.append(part + \"\\n\")\n",
        "\n",
        "        text = \"\".join(processed_text_parts)\n",
        "        # Consolidate multiple blank lines resulting from joins or original HTML structure\n",
        "        text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text).strip()\n",
        "\n",
        "        if not text:\n",
        "            print(f\"   ❌ Extracted text was empty for URL {page_url} after cleaning and processing.\")\n",
        "            return f\"Error: Extracted text was empty for URL {page_url} after cleaning. The article might be primarily composed of images or have an unrecognized format.\"\n",
        "\n",
        "        # Cap the length of the raw text returned to the agent.\n",
        "        # The agent will then summarize this. This cap prevents overwhelming the agent.\n",
        "        max_raw_text_length = 150000 # Characters (allows for a fairly substantial article)\n",
        "        full_text_content = text[:max_raw_text_length]\n",
        "        if len(text) > max_raw_text_length:\n",
        "            full_text_content += \"\\n\\n... [CONTENT TRUNCATED BY TOOL DUE TO EXCEEDING MAX LENGTH]\"\n",
        "            print(f\"   ⚠️ Content from {page_url} was truncated by radiopaedia_content_extraction_tool due to its length ({len(text)} chars).\")\n",
        "\n",
        "        print(f\"   ✅ Successfully extracted content from {page_url}. Final length for agent: {len(full_text_content)} chars.\")\n",
        "        return full_text_content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Unexpected error occurred while parsing content from Radiopaedia URL {page_url}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Log the full traceback for debugging\n",
        "        return f\"Error: An unexpected error occurred while parsing content from Radiopaedia URL {page_url}: {str(e)}\""
      ],
      "metadata": {
        "id": "nC76oCYK35mF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Test: radiopaedia_content_extraction_tool ---\n",
        "\n",
        "print(\"--- Testing Radiopaedia Content Extraction Tool ---\")\n",
        "# Ensure the tool function exists (defined in previous cells)\n",
        "if 'radiopaedia_content_extraction_tool' in locals():\n",
        "    test_url = \"https://radiopaedia.org/articles/stroke?lang=us\"\n",
        "    print(f\"Attempting to extract content from URL: {test_url}\")\n",
        "\n",
        "    # Call the tool directly\n",
        "    extraction_result = radiopaedia_content_extraction_tool(page_url=test_url)\n",
        "\n",
        "    if isinstance(extraction_result, str):\n",
        "        if extraction_result.startswith(\"Error:\"):\n",
        "            print(f\"\\n❌ Test Result (Error): {extraction_result}\")\n",
        "        else:\n",
        "            print(f\"\\n✅ Test Result (Success!): Extracted Content (first 600 chars):\\n\")\n",
        "            print(extraction_result[:600])\n",
        "            if len(extraction_result) > 600:\n",
        "                print(\"\\n...\")\n",
        "            if \"[CONTENT TRUNCATED BY TOOL DUE TO EXCEEDING MAX LENGTH]\" in extraction_result:\n",
        "                 print(\"\\n(Note: Full content was truncated by the tool)\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Test Error: Unexpected return type from tool: {type(extraction_result)}\")\n",
        "else:\n",
        "    print(\"❌ Cannot run test: `radiopaedia_content_extraction_tool` function not defined.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# --- Optional: Test with a non-article URL (should fail gracefully) ---\n",
        "print(\"\\n--- Testing Radiopaedia Tool with Invalid URL ---\")\n",
        "if 'radiopaedia_content_extraction_tool' in locals():\n",
        "    invalid_url = \"https://radiopaedia.org/cases\" # Not an article URL\n",
        "    print(f\"Attempting to extract content from invalid URL: {invalid_url}\")\n",
        "    error_result = radiopaedia_content_extraction_tool(page_url=invalid_url)\n",
        "    if isinstance(error_result, str) and error_result.startswith(\"Error:\"):\n",
        "        print(f\"✅ Test Result (Expected Error): {error_result}\")\n",
        "    else:\n",
        "        print(f\"❌ Test Result (Unexpected): Tool did not return expected error for invalid URL. Output: {error_result}\")\n",
        "else:\n",
        "    print(\"❌ Cannot run test: `radiopaedia_content_extraction_tool` function not defined.\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sci8i07Nzui",
        "outputId": "5aa7464c-4f5c-490b-f3bb-522f104796cd",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Radiopaedia Content Extraction Tool ---\n",
            "Attempting to extract content from URL: https://radiopaedia.org/articles/stroke?lang=us\n",
            "Radiopaedia Content Extractor: Attempting to fetch URL: https://radiopaedia.org/articles/stroke?lang=us\n",
            "   ✅ Successfully extracted content from https://radiopaedia.org/articles/stroke?lang=us. Final length for agent: 763 chars.\n",
            "\n",
            "✅ Test Result (Success!): Extracted Content (first 600 chars):\n",
            "\n",
            "A stroke is a clinical diagnosis that refers to a sudden onset focal neurological deficit of presumed vascular origin.\n",
            "\n",
            "Stroke is generally divided into two broad categories 1,2 :\n",
            "ischemic stroke (87%)\n",
            "hemorrhagic stroke (13%)\n",
            "Terminology\n",
            "The term \"stroke\" is ambiguous and care must be taken to ensure that precise terminology is used. This is particularly the case for \"hemorrhagic stroke\" which although is often used synonymously with intracerebral hemorrhage , has a broader definition to many authors and organizations to also include subarachnoid hemorrhage 1 . Additionally, \"hemorrhagic stro\n",
            "\n",
            "...\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Testing Radiopaedia Tool with Invalid URL ---\n",
            "Attempting to extract content from invalid URL: https://radiopaedia.org/cases\n",
            "Radiopaedia Content Extractor: Attempting to fetch URL: https://radiopaedia.org/cases\n",
            "✅ Test Result (Expected Error): Error: Invalid or non-Radiopaedia article URL provided. URL must start with 'http(s)://radiopaedia.org/articles/'.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Local PDF RAG (Retrieval-Augmented Generation) Tool\n",
        "\n",
        "This tool will allow our agent to search for information within the PDF documents you've stored in the SharedRadiologyPDFs folder on Google Drive. It involves several sub-steps:\n",
        "1. Load and Chunk PDFs: Read text from all PDFs and split it into smaller, manageable chunks.\n",
        "2. Embed Chunks: Convert each text chunk into a numerical vector (embedding) using a sentence transformer model.\n",
        "3. Build FAISS Index: Create a FAISS index from these embeddings for fast similarity searching.\n",
        "4. Query Function: The actual tool function will take a user's query, embed it, and use the FAISS index to find the most relevant text chunks from the PDFs.\n",
        "\n",
        "We'll define helper functions for loading/chunking and index building, then the SmolAgent tool."
      ],
      "metadata": {
        "id": "TxBtXd416489"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper function: PDF Loading and Chunking\n",
        "TThis function, load_and_chunk_pdfs, is responsible for processing your local PDF library:\n",
        "\n",
        "1. It locates all PDF files within the SharedRadiologyPDFs folder in your Google Drive.\n",
        "2. For each PDF, it extracts the raw text content.\n",
        "3. This text is then divided into smaller, overlapping \"chunks.\" Chunking is important because LLMs have context limits, and processing smaller segments improves the relevance of search results.\n",
        "4. Crucially, for each chunk, detailed metadata is stored:\n",
        "  - source_pdf_name: The filename of the PDF it came from.\n",
        "  - chunk_index_in_doc: Its sequential position within that specific PDF.\n",
        "  - global_chunk_index: A unique index for the chunk across all processed PDFs. This global index is vital for the retrieve_neighboring_chunks_tool to function correctly.\n",
        "\n",
        "  The output of this function (a list of all text chunks and a parallel list of their metadata) forms the foundation of our RAG system's knowledge base."
      ],
      "metadata": {
        "id": "TSWoPGVv7HYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def load_and_chunk_pdfs(\n",
        "    pdf_folder_path: Path,\n",
        "    chunk_size: int = 800,  # Target character length for each chunk\n",
        "    chunk_overlap: int = 150 # Number of characters to overlap between chunks\n",
        ") -> tuple[list[str], list[dict]]:\n",
        "    \"\"\"\n",
        "    Loads all PDF files from a specified folder, extracts their text content,\n",
        "    and splits this text into manageable, overlapping chunks.\n",
        "    Each chunk is stored along with detailed metadata for later retrieval and context expansion.\n",
        "\n",
        "    Args:\n",
        "        pdf_folder_path (Path): The path to the folder containing PDF files.\n",
        "        chunk_size (int): The target size for each text chunk in characters.\n",
        "        chunk_overlap (int): The number of characters to overlap between consecutive chunks\n",
        "                             to ensure context isn't lost at chunk boundaries.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[str], list[dict]]: A tuple containing:\n",
        "            - A list of all text chunks (strings) extracted from all PDFs.\n",
        "            - A parallel list of metadata dictionaries, one for each chunk, containing\n",
        "              'source_pdf_name', 'chunk_index_in_doc', and 'global_chunk_index'.\n",
        "    \"\"\"\n",
        "    all_chunks_text: list[str] = []\n",
        "    all_chunks_metadata: list[dict] = []\n",
        "    current_global_chunk_index: int = 0 # Initialize global counter\n",
        "\n",
        "    if not pdf_folder_path.exists() or not pdf_folder_path.is_dir():\n",
        "        print(f\"⚠️ PDF folder not found or is not a directory: {pdf_folder_path}. Cannot load PDFs.\")\n",
        "        return [], []\n",
        "\n",
        "    pdf_files_in_folder = list(pdf_folder_path.glob(\"*.pdf\"))\n",
        "    if not pdf_files_in_folder:\n",
        "        print(f\"⚠️ No PDF files (*.pdf) found in the specified folder: {pdf_folder_path}.\")\n",
        "        return [], []\n",
        "\n",
        "    print(f\"Found {len(pdf_files_in_folder)} PDF file(s) in {pdf_folder_path}. Starting processing...\")\n",
        "\n",
        "    for pdf_path in pdf_files_in_folder:\n",
        "        print(f\"  Processing PDF: {pdf_path.name}...\")\n",
        "        try:\n",
        "            reader = PdfReader(pdf_path)\n",
        "            full_pdf_text = \"\"\n",
        "            for i, page in enumerate(reader.pages):\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    full_pdf_text += page_text.strip() + \"\\n\" # Add a newline separator between pages\n",
        "                # else:\n",
        "                #     print(f\"    - Note: Page {i+1} in {pdf_path.name} had no extractable text.\")\n",
        "\n",
        "            if not full_pdf_text.strip():\n",
        "                print(f\"    - Warning: No text could be extracted from {pdf_path.name} overall.\")\n",
        "                continue\n",
        "\n",
        "            # Basic text cleaning: reduce multiple spaces/newlines\n",
        "            cleaned_pdf_text = re.sub(r'\\s\\s+', ' ', full_pdf_text)\n",
        "            cleaned_pdf_text = re.sub(r'\\n\\n+', '\\n', cleaned_pdf_text).strip()\n",
        "\n",
        "            # Chunking logic for the current PDF document\n",
        "            start_char_index = 0\n",
        "            chunk_index_within_this_doc = 0 # Reset for each new document\n",
        "\n",
        "            num_chunks_from_this_doc = 0\n",
        "            while start_char_index < len(cleaned_pdf_text):\n",
        "                end_char_index = min(start_char_index + chunk_size, len(cleaned_pdf_text))\n",
        "                chunk_text_content = cleaned_pdf_text[start_char_index:end_char_index]\n",
        "\n",
        "                all_chunks_text.append(chunk_text_content) # Add to global list of texts\n",
        "                all_chunks_metadata.append({\n",
        "                    'source_pdf_name': pdf_path.name,\n",
        "                    'chunk_index_in_doc': chunk_index_within_this_doc,\n",
        "                    'global_chunk_index': current_global_chunk_index,\n",
        "                    # 'text_preview': chunk_text_content[:60].replace('\\n', ' ') + \"...\" # Useful for debugging\n",
        "                })\n",
        "\n",
        "                chunk_index_within_this_doc += 1\n",
        "                current_global_chunk_index += 1 # Increment global index for every chunk\n",
        "                num_chunks_from_this_doc +=1\n",
        "\n",
        "                # Determine start of next chunk considering overlap\n",
        "                next_start = start_char_index + chunk_size - chunk_overlap\n",
        "                # If the remaining text is very small, just break to avoid a tiny last chunk\n",
        "                if len(cleaned_pdf_text) - next_start < (chunk_size * 0.20) and next_start < len(cleaned_pdf_text) : # If less than 20% of chunk size remains\n",
        "                     if start_char_index + chunk_size < len(cleaned_pdf_text): # if current chunk wasn't the last possible full chunk\n",
        "                          # Force the last chunk to grab all remaining text\n",
        "                          chunk_text_content_final = cleaned_pdf_text[start_char_index:] # Grab from current start to end\n",
        "                          all_chunks_text[-1] = chunk_text_content_final # Overwrite last appended chunk\n",
        "                          # Update metadata for this now potentially larger last chunk if needed, or just accept previous metadata\n",
        "                          print(f\"    - Adjusted last chunk of {pdf_path.name} to include all remaining text.\")\n",
        "                     break # Exit loop after processing the (potentially adjusted) last chunk\n",
        "                start_char_index = next_start\n",
        "\n",
        "\n",
        "            print(f\"    - Extracted {num_chunks_from_this_doc} chunks from {pdf_path.name}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    - ❌ Error processing PDF file {pdf_path.name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc() # Log full error for diagnosis\n",
        "\n",
        "    print(f\"✅ PDF processing complete. Total {len(all_chunks_text)} chunks created from all documents.\")\n",
        "    if len(all_chunks_text) != len(all_chunks_metadata):\n",
        "        # This should ideally not happen with the current logic\n",
        "        print(f\"    🚨 CRITICAL INTERNAL WARNING: Mismatch in chunk text ({len(all_chunks_text)}) and metadata ({len(all_chunks_metadata)}) counts! This will cause issues.\")\n",
        "    return all_chunks_text, all_chunks_metadata"
      ],
      "metadata": {
        "id": "egBWxLU-7G-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Function: Embedding and FAISS Index Building Function\n",
        "This function takes the text chunks, generates embeddings using a SentenceTransformer model, and builds a FAISS index for efficient searching. These (embedder, index, chunks, metadata) will be stored globally for the tool to use."
      ],
      "metadata": {
        "id": "8CQRhCOu8Z_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Global variables for the RAG system components\n",
        "# These will be initialized by build_pdf_rag_system()\n",
        "pdf_rag_embedder: SentenceTransformer | None = None\n",
        "pdf_rag_index: faiss.Index | None = None\n",
        "pdf_rag_chunks: list[str] = []\n",
        "pdf_rag_metadata: list[dict] = []\n",
        "\n",
        "def build_pdf_rag_system(\n",
        "    chunks: list[str],\n",
        "    metadata: list[dict],\n",
        "    embedding_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\" # A good default\n",
        "):\n",
        "    \"\"\"\n",
        "    Builds the FAISS index and initializes the embedder for the PDF RAG system.\n",
        "\n",
        "    Args:\n",
        "        chunks (list[str]): The list of text chunks from PDFs.\n",
        "        metadata (list[dict]): The list of metadata corresponding to the chunks.\n",
        "        embedding_model_name (str): Name of the SentenceTransformer model to use.\n",
        "    \"\"\"\n",
        "    global pdf_rag_embedder, pdf_rag_index, pdf_rag_chunks, pdf_rag_metadata\n",
        "\n",
        "    if not chunks:\n",
        "        print(\"⚠️ No chunks provided to build the PDF RAG system. It will not be functional.\")\n",
        "        return\n",
        "\n",
        "    pdf_rag_chunks = chunks\n",
        "    pdf_rag_metadata = metadata\n",
        "\n",
        "    try:\n",
        "        print(f\"Initializing PDF RAG embedder: {embedding_model_name}...\")\n",
        "        pdf_rag_embedder = SentenceTransformer(embedding_model_name, device=device)\n",
        "        print(\"✅ Embedder initialized.\")\n",
        "\n",
        "        print(\"Generating embeddings for PDF chunks (this may take a while for many chunks)...\")\n",
        "        # Encode in batches if memory is a concern, though for moderate sizes direct encoding is fine\n",
        "        embeddings = pdf_rag_embedder.encode(\n",
        "            pdf_rag_chunks,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True, # FAISS expects numpy arrays\n",
        "            batch_size=32 # Adjust batch size based on available VRAM/RAM\n",
        "        )\n",
        "\n",
        "        if embeddings is None or embeddings.shape[0] == 0:\n",
        "            print(\"❌ Error: Failed to generate embeddings for PDF chunks.\")\n",
        "            pdf_rag_index = None # Ensure index is None if embedding fails\n",
        "            return\n",
        "\n",
        "        print(f\"✅ Embeddings generated. Shape: {embeddings.shape}\")\n",
        "\n",
        "        dimension = embeddings.shape[1]\n",
        "        # Using IndexFlatL2 for simplicity; other FAISS indices exist for larger datasets\n",
        "        pdf_rag_index = faiss.IndexFlatL2(dimension)\n",
        "        # FAISS expects float32 for IndexFlatL2\n",
        "        pdf_rag_index.add(embeddings.astype(np.float32))\n",
        "\n",
        "        print(f\"✅ FAISS index built successfully with {pdf_rag_index.ntotal} vectors.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error building PDF RAG system: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        pdf_rag_embedder = None\n",
        "        pdf_rag_index = None\n",
        "        pdf_rag_chunks = [] # Clear chunks if system build fails\n",
        "        pdf_rag_metadata = []"
      ],
      "metadata": {
        "id": "kiqLqAjI8ULF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the RAG Search Index\n",
        "Once we have the text chunks and their metadata, we need to make them searchable. This involves:\n",
        "\n",
        "1.  **Embedding Generation**: Using a `SentenceTransformer` model (e.g., `all-MiniLM-L6-v2`), each text chunk is converted into a dense vector embedding. These embeddings capture the semantic meaning of the text.\n",
        "\n",
        "2.  **FAISS Index Creation**: These embeddings are then loaded into a FAISS (Facebook AI Similarity Search) index. FAISS allows for very fast and efficient searching of the most similar embeddings (and thus, text chunks) to a given query embedding.\n",
        "\n",
        "The `build_pdf_rag_system` function handles these steps. The resulting `pdf_rag_embedder` and `pdf_rag_index`, along with the `pdf_rag_chunks` and `pdf_rag_metadata`, are stored as global variables for use by our RAG tools. This indexing process is typically done once when the notebook starts or when the PDF library changes."
      ],
      "metadata": {
        "id": "xzZK_X7w8kM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Global variables for the RAG system components\n",
        "pdf_rag_embedder: SentenceTransformer | None = None\n",
        "pdf_rag_index: faiss.Index | None = None\n",
        "pdf_rag_chunks: list[str] = []       # Will store text of all chunks\n",
        "pdf_rag_metadata: list[dict] = []    # Will store metadata for each chunk\n",
        "\n",
        "def build_pdf_rag_system(\n",
        "    chunks_text_list: list[str],\n",
        "    chunks_metadata_list: list[dict],\n",
        "    embedding_model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Builds the FAISS index from text chunks and initializes the sentence embedder.\n",
        "    Stores the embedder, index, chunks, and metadata in global variables.\n",
        "    \"\"\"\n",
        "    global pdf_rag_embedder, pdf_rag_index, pdf_rag_chunks, pdf_rag_metadata\n",
        "\n",
        "    if not chunks_text_list or not chunks_metadata_list or len(chunks_text_list) != len(chunks_metadata_list):\n",
        "        print(\"⚠️ No chunks provided or mismatch between chunks and metadata. PDF RAG system will not be functional.\")\n",
        "        pdf_rag_chunks, pdf_rag_metadata = [], [] # Clear any partial data\n",
        "        return\n",
        "\n",
        "    # Store the provided chunks and metadata globally\n",
        "    pdf_rag_chunks = chunks_text_list\n",
        "    pdf_rag_metadata = chunks_metadata_list\n",
        "    print(f\"Stored {len(pdf_rag_chunks)} chunks and metadata globally for RAG system.\")\n",
        "\n",
        "    try:\n",
        "        print(f\"Initializing PDF RAG sentence embedder: {embedding_model_name}...\")\n",
        "        pdf_rag_embedder = SentenceTransformer(embedding_model_name, device=device)\n",
        "        print(\"✅ Embedder initialized.\")\n",
        "\n",
        "        print(\"Generating embeddings for all PDF chunks (this may take a while for large libraries)...\")\n",
        "        embeddings = pdf_rag_embedder.encode(\n",
        "            pdf_rag_chunks,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True,\n",
        "            batch_size=32 # Adjust based on available VRAM/RAM if performance issues arise\n",
        "        )\n",
        "\n",
        "        if embeddings is None or embeddings.shape[0] == 0:\n",
        "            print(\"❌ Error: Failed to generate embeddings for PDF chunks. RAG system will be impaired.\")\n",
        "            pdf_rag_index = None\n",
        "            return\n",
        "\n",
        "        print(f\"✅ Embeddings generated successfully. Shape: {embeddings.shape}\")\n",
        "\n",
        "        dimension = embeddings.shape[1]\n",
        "        # Using IndexFlatL2 for simplicity; other FAISS indices offer different trade-offs.\n",
        "        pdf_rag_index = faiss.IndexFlatL2(dimension)\n",
        "        # FAISS expects float32 for IndexFlatL2. Ensure embeddings are in this format.\n",
        "        pdf_rag_index.add(embeddings.astype(np.float32))\n",
        "\n",
        "        print(f\"✅ FAISS index built successfully with {pdf_rag_index.ntotal} vectors.\")\n",
        "        print(\"   PDF RAG System is ready for querying.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error occurred while building the PDF RAG system: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Reset global RAG components on failure\n",
        "        pdf_rag_embedder = None\n",
        "        pdf_rag_index = None\n",
        "        pdf_rag_chunks = []\n",
        "        pdf_rag_metadata = []\n",
        "        print(\"   PDF RAG system components have been reset due to build failure.\")"
      ],
      "metadata": {
        "id": "IlgB-FKgKrf3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize RAG System (Call the Loaders and Builders)\n",
        "\n",
        "This cell executes the functions defined above to load your PDFs, chunk the text, generate embeddings, and build the searchable FAISS index. This process runs once and makes the RAG system ready for queries. Ensure your `SharedRadiologyPDFs` folder (defined by `PDF_FOLDER_PATH` in Section 1) contains your reference documents.\n"
      ],
      "metadata": {
        "id": "aTKrNOCuKxi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "print(\"\\n--- Initializing Local PDF RAG System ---\")\n",
        "# Check if already initialized to avoid re-processing if cell is run multiple times,\n",
        "# though re-running might be desired if PDFs change.\n",
        "# For simplicity, we'll allow re-initialization here.\n",
        "\n",
        "# Clear previous RAG data if any, to ensure a fresh build\n",
        "pdf_rag_embedder, pdf_rag_index, pdf_rag_chunks, pdf_rag_metadata = None, None, [], []\n",
        "\n",
        "temp_loaded_chunks, temp_loaded_metadata = load_and_chunk_pdfs(PDF_FOLDER_PATH)\n",
        "if temp_loaded_chunks and temp_loaded_metadata: # Ensure both were loaded\n",
        "    build_pdf_rag_system(temp_loaded_chunks, temp_loaded_metadata)\n",
        "else:\n",
        "    print(\"⚠️ PDF RAG System could not be built: No PDF chunks or metadata were loaded. Check PDF folder and loading function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760,
          "referenced_widgets": [
            "266620d475d84a5586e22d0bf21364b5",
            "f98ae51b4a054d41b432cefd5564b89e",
            "4f24eaada87c4ee99669cab82bffde5c",
            "477edb5350dd479e8256336d0540fcd7",
            "e33b135c9d0e426c9bb5d8935b67493e",
            "6fc19181841f4efbaaa01ae1b3d3567d",
            "f6d14adc46da4f75994b4bd20bb8a440",
            "343af3fa46b442aba6d569efe2b26460",
            "acc84c4704e24800808ddc94fe38411e",
            "73da7551c6424bfd8eaea8d31041aa84",
            "3c83a29ec3f94d019bb137f215b87d5c",
            "eecfe7a5a18d42db9f2ce212d2062f36",
            "dfcb4d06eda74913962fc0e06e4541c3",
            "6eacafac22394cdf862334a27f917157",
            "06febb2f316645ed8ff20c79a6861072",
            "8b7ab76268af4ef7acb6d4b8d112e7df",
            "7459935e448a4bc983a51b93e82081a7",
            "c09d13946dbc47c088735edee2d4cd5a",
            "a986c4e040f243e8a6edabfdf59dfcde",
            "2a3a3ab485624bc89a50a2d74c828597",
            "77db5dfaa74142ea8a3a3b30ed894f77",
            "75bc22f7ec5b4cd2b230594a7f95b9e1",
            "f65e948a790d47ecac9557672620d615",
            "89f73480267b403692a9e7fc5e4a3778",
            "edefa65b8b1146be83b7801a87b72f28",
            "37145f9f0f9942eb8eec38b4ba73bd5a",
            "8b12dc0501e043cfb2a6bf515d028259",
            "4a097caf00514dbcaa6b7d9579fb52c5",
            "17c4ce0d6b1b4797ab748c2cd60563ce",
            "b905f1dd4406477683cd7642dc7dc8a8",
            "8bc94c2e64b947e4b75759ba0d4c471a",
            "54f2f692a5d64cc49c94b4223aa47187",
            "3be97350772947a5bbdb303126a73616",
            "7e9d840769204ac68ff74302163abd06",
            "3d3551971da94101a2465ec47cfb0131",
            "007900d0367f4a26a5419b100d6d1429",
            "4ff989de411b4e57b201745008a80500",
            "605816660f6a4972829795ac22a4ca53",
            "017ea207b1e8405795a1b5e2b7d1bb69",
            "92707f8a1c284664b7780cc91ac16e9d",
            "53c900393bca46729699572ab0add119",
            "07f850d623b646329232f17e2c3e76cb",
            "374d60eec80a490eb556dc9808599cce",
            "54f803bbdc464f18969b137c4a0561b2",
            "123521b0515346039420b76b55c53860",
            "9f5f2f1fd91042339479e33cbab0b235",
            "b8dd95d2b8174014ae26d17a41395271",
            "0a82e318a5b24ee68077565792a2362d",
            "3eb7eaafa4d44d9d870d8bf56e3a006b",
            "2bc6188dd268460083a1ded6f474687a",
            "a0e74b5c74a54cddbb21e3ad17c617ac",
            "83511826369c4116b1c9a7a439816225",
            "634dc12b19dd4c158b4da8d81ddbe4d9",
            "56bef8e0e75842c4be5ec56e4d43c35f",
            "4244a1d3b3074f95b614280bc0d9d168",
            "9397a79f69bb4b8095df9fbcde7d28bb",
            "a3ff7b2530664f3a9a25534b01015c2a",
            "3d3c4e45a64b43728b46e9ee071fc4d5",
            "1a8475b8e0e044bf95a53ad0d85b4c19",
            "8ecd721b30444c4695a0f4b1bda996c8",
            "2230ca957eb046c485741be9a29baa36",
            "8e14a3000cde48768160da742b8589cc",
            "f1fa872c2d334621920bb2609e9ebb88",
            "6497ce9a11244278a478258961554988",
            "0bb44e06b3034efcb5c10f86bb83453c",
            "5309c45580b34cbe9168480bc13eab3d",
            "b3eede86757645b397eebbd5ee4695dc",
            "fb49423791e34c05b5cfba8b0a652254",
            "9fe528296cec4b25a7ec90206e0c2e01",
            "1335ac47d67840e1b6b827aa1dbd8985",
            "60bcd320378843f39f1bb4a3a1ffa28b",
            "f49eda891b19485ea372cb9ac0ba8f47",
            "1ae6d40927544990a4064b0c14a454cd",
            "95585e8d4b2e43eaa481e43102a302d1",
            "f566a10837b14fe981f4a64afe03e4d1",
            "fc39b128cd544c69b327e78eabe86420",
            "b88b978c16374d67a68efbfc48707275",
            "dda89d070519437a849f6220f77feade",
            "34771befd49548399868056129e4de04",
            "47803afb6a8041ce97e427d2895c2296",
            "233c867b81c9403ca44809fc3c1165e2",
            "d3b9f277767e4960899e2032e3733ccf",
            "4db1051c9dc8496d91908bccf127f549",
            "3ecf418cc24342f9a3a980edf8c32eaa",
            "b6fa6f925f17474f956dc22b6ab55ce5",
            "1f23c52f16de4fb998e682b01c60572a",
            "3c608a129ff54977b7abc5a1d2e342bc",
            "789bd27a98df4791a860b82bbb1ade53",
            "5078d704cdd04ec4b1605ac7791b5971",
            "c36a89ae5b0b4e31995de0d2009971e4",
            "9901b5319e284b4694a0451eaca6254b",
            "ff81fb1f991a4f84af0d30c4e2a02f9f",
            "4bd4f32877ac47a281bbf13c7810b992",
            "c625896d787b404f9c021d7086ed888f",
            "7ab0d3c03a964d07bfe165efa31b5142",
            "d49f6e7665d04d7d8b3c2b5f8d2b3e10",
            "b391a14a59f8444f97fd6f1b00ae98f6",
            "332cac79136c4165864e14735b86e4c1",
            "cb439590c6b94e8eb2f56520f943ce5d",
            "6d1178fa583d4a45b06aab4ca07f7c02",
            "d1985a25a8da4dca931cf8af78459585",
            "2f2a620d13ed48c0ab42064946b31350",
            "a1d563faf0104c038dfd33f0f826b696",
            "7f57ee095a004293a84cb5fd0bb95628",
            "665be036c2c4451e96dc7b1899c1c184",
            "7efdf40089324b98b339b27d4ff27661",
            "c3346582eaec44958cc4a6a7321aabc0",
            "63e6c1bf7a8d44b786b6f82fb77c2228",
            "8795590b17a84091a8b572dc201ab8f6",
            "76a3244073734b3c92989179341ac867",
            "7bc716d25e9c455eaca5d2644ba91ced",
            "90e75ef764164eb8bd3d1e761d60eb82",
            "16f6cd63e0e5467ea3f81d95477f14e2",
            "bda01d79e9e94042a4103d0817d38818",
            "6741953a7a35442abddb468e3ee3f53a",
            "a382f798e08948049ae1953f4cf7e2cf",
            "61182b1df7be4d4588a56d2c4d6c1e62",
            "845b4611b51e4af1821914569d01e66f",
            "186ecf9ed10f499a8ae514003f788e97",
            "62f5907684094693ac4cfbfd3b69738b",
            "de2c7ac7465d4085aff76671a131d50a",
            "7f751b8cf19f4efd973fc9fe02094a8d",
            "f17ccb1071414ea689b5809839bc2b1d",
            "040fdb78c7e642fca9685ee10601a678",
            "3c7a33174d2b4605b7bc375eed4d784d",
            "c8caea775e06441eaeb3534b754bd42e",
            "edcb10a86a5146cda0ee9cc5e84892e6",
            "6776f81882e94af7907bb9ef585bc0cc",
            "ecbca424ca244c7687d8ec247178d09b",
            "f0440cacd809446899e50dff6d910257",
            "b1d8af5872074e67acae6553d3e8be28",
            "010144c3df2b42ce8dafa7af1afb1e59"
          ]
        },
        "id": "DKGFFIK68e5g",
        "outputId": "9f573284-f442-4197-9029-5f6035c728f2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initializing Local PDF RAG System ---\n",
            "Found 3 PDF file(s) in /content/drive/MyDrive/RadiologyMultiAgentColab/SharedRadiologyPDFs. Starting processing...\n",
            "  Processing PDF: AD-M2400 ARIA in the ED infographic.pdf...\n",
            "    - Extracted 11 chunks from AD-M2400 ARIA in the ED infographic.pdf.\n",
            "  Processing PDF: ARIA_differential_diagnosis.pdf...\n",
            "    - Extracted 10 chunks from ARIA_differential_diagnosis.pdf.\n",
            "  Processing PDF: jksr-86-17-s001.pdf...\n",
            "    - Extracted 64 chunks from jksr-86-17-s001.pdf.\n",
            "✅ PDF processing complete. Total 85 chunks created from all documents.\n",
            "Stored 85 chunks and metadata globally for RAG system.\n",
            "Initializing PDF RAG sentence embedder: sentence-transformers/all-MiniLM-L6-v2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "266620d475d84a5586e22d0bf21364b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eecfe7a5a18d42db9f2ce212d2062f36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f65e948a790d47ecac9557672620d615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e9d840769204ac68ff74302163abd06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "123521b0515346039420b76b55c53860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9397a79f69bb4b8095df9fbcde7d28bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3eede86757645b397eebbd5ee4695dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dda89d070519437a849f6220f77feade"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5078d704cdd04ec4b1605ac7791b5971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d1178fa583d4a45b06aab4ca07f7c02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bc716d25e9c455eaca5d2644ba91ced"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embedder initialized.\n",
            "Generating embeddings for all PDF chunks (this may take a while for large libraries)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f751b8cf19f4efd973fc9fe02094a8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Embeddings generated successfully. Shape: (85, 384)\n",
            "✅ FAISS index built successfully with 85 vectors.\n",
            "   PDF RAG System is ready for querying.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tool definition\n",
        "\n",
        "After we defined the helper functions, built our RAG search index, and initalized the RAG system, it is finally time to define our local PDF RAG tool.\n",
        "\n",
        "This tool is the agent's interface to search the indexed PDF content:\n",
        "1. It takes a query (e.g., a specific imaging finding) and an optional top_k (number of results to return).\n",
        "2. The query is converted into an embedding using the same sentence transformer model.\n",
        "3. This query embedding is used to search the FAISS index for the top_k most semantically similar text chunks from the PDFs.\n",
        "4. Crucially, the tool now returns its findings as a JSON string. This structured output contains a list of \"result\" objects. Each object provides:\n",
        "  - text: The actual content of the retrieved chunk.\n",
        "  - source_pdf_name: The name of the PDF file this chunk originated from.\n",
        "  - global_chunk_index: The unique global index of this chunk across all documents. This is essential for the retrieve_neighboring_chunks_tool to locate and provide further context.\n",
        "  - chunk_index_in_doc: The index of the chunk within its original PDF.\n",
        "  - relevance_score (optional): A score indicating how similar the chunk is to the query.\n",
        "  \n",
        "This JSON output allows the InternalReferenceExpertAgent (which is a CodeAgent) to easily parse these results and use the global_chunk_index for subsequent context expansion.\n"
      ],
      "metadata": {
        "id": "PH2oifdZA3O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "@tool\n",
        "def query_internal_references_tool(query: str, top_k: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Searches the indexed internal PDF reference documents for information\n",
        "    relevant to the given query (e.g., an imaging finding).\n",
        "    Uses semantic search over text chunks extracted from these PDFs.\n",
        "\n",
        "    Args:\n",
        "        query (str): The question or imaging finding to search for in the internal references.\n",
        "        top_k (int): The maximum number of relevant text chunks to retrieve.\n",
        "                     Defaults to 3, with a maximum of 5 allowed by this tool.\n",
        "\n",
        "    Returns:\n",
        "        str: A JSON string.\n",
        "             If successful, this JSON string contains an object with a \"results\" key.\n",
        "             The value of \"results\" is a list of retrieved chunk objects. Each chunk object\n",
        "             includes 'text', 'source_pdf_name', 'global_chunk_index', 'chunk_index_in_doc',\n",
        "             and 'relevance_score'.\n",
        "             If an error occurs or no relevant results are found, the JSON string will contain\n",
        "             an object with an \"error\" key and a descriptive message.\n",
        "    \"\"\"\n",
        "    print(f\"Local PDF RAG Tool: Received query '{query}', top_k={top_k}\")\n",
        "    global pdf_rag_index, pdf_rag_embedder, pdf_rag_chunks, pdf_rag_metadata # Access global RAG components\n",
        "\n",
        "    if not all([pdf_rag_index, pdf_rag_embedder, pdf_rag_chunks, pdf_rag_metadata]):\n",
        "        # Check if any essential component is None or empty\n",
        "        print(\"   ❌ Error: Local PDF RAG system is not fully initialized or critical data (index, embedder, chunks, metadata) is missing.\")\n",
        "        return json.dumps({\"error\": \"Local PDF RAG system is not fully initialized. Please check setup and PDF loading.\"})\n",
        "    if not query or not query.strip():\n",
        "        print(\"   ❌ Error: No query provided for internal reference lookup.\")\n",
        "        return json.dumps({\"error\": \"No query provided for internal reference lookup.\"})\n",
        "\n",
        "    try:\n",
        "        # Sanitize top_k to be within a reasonable range (e.g., 1 to 5)\n",
        "        k = min(max(1, int(top_k)), 5)\n",
        "\n",
        "        query_embedding = pdf_rag_embedder.encode([query], convert_to_numpy=True)\n",
        "        # FAISS index expects float32\n",
        "        if query_embedding.dtype != np.float32:\n",
        "            query_embedding = query_embedding.astype(np.float32)\n",
        "\n",
        "        # Perform the search using the FAISS index\n",
        "        distances, indices = pdf_rag_index.search(query_embedding, k)\n",
        "\n",
        "        retrieved_items = []\n",
        "        # indices[0] contains the list of global_chunk_indexes for the top_k results\n",
        "        if indices.size > 0 and indices[0,0] != -1: # FAISS returns -1 if fewer than k items found\n",
        "            for i in range(indices.shape[1]): # Iterate through the found indices\n",
        "                global_idx = indices[0, i]\n",
        "                if global_idx == -1: # No more valid items found for this query\n",
        "                    break\n",
        "\n",
        "                # Ensure the index is valid for our lists\n",
        "                if 0 <= global_idx < len(pdf_rag_chunks) and global_idx < len(pdf_rag_metadata):\n",
        "                    chunk_text_content = pdf_rag_chunks[global_idx]\n",
        "                    meta_info = pdf_rag_metadata[global_idx]\n",
        "\n",
        "                    retrieved_items.append({\n",
        "                        \"text\": chunk_text_content.strip(),\n",
        "                        \"source_pdf_name\": meta_info.get('source_pdf_name', 'Unknown Source'),\n",
        "                        \"global_chunk_index\": meta_info.get('global_chunk_index', -1), # Should match global_idx\n",
        "                        \"chunk_index_in_doc\": meta_info.get('chunk_index_in_doc', -1),\n",
        "                        \"relevance_score\": float(distances[0, i]) if (distances is not None and distances.shape[1] > i) else None # Similarity score\n",
        "                    })\n",
        "                else:\n",
        "                    print(f\"   ⚠️ Warning: Invalid global_chunk_index {global_idx} encountered from FAISS search. Total chunks available: {len(pdf_rag_chunks)}. This result will be skipped.\")\n",
        "\n",
        "        if not retrieved_items:\n",
        "            print(f\"   ℹ️ No relevant chunks found for '{query}' in internal references after processing FAISS results.\")\n",
        "            return json.dumps({\"error\": f\"No relevant information found in internal references for the query: '{query}'.\"})\n",
        "\n",
        "        print(f\"   ✅ Local PDF RAG Tool: Retrieved {len(retrieved_items)} structured items for '{query}'.\")\n",
        "        return json.dumps({\n",
        "            \"query\": query, # Echo back the query for context\n",
        "            \"results\": retrieved_items,\n",
        "            \"message\": f\"Successfully retrieved {len(retrieved_items)} relevant chunks from internal references.\"\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Local PDF RAG Tool: An unexpected error occurred during search for '{query}': {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Log full traceback\n",
        "        return json.dumps({\"error\": f\"An unexpected error occurred while performing search in internal references for query '{query}': {str(e)}\"})"
      ],
      "metadata": {
        "id": "D1kuHOYx9Ybr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Test: query_internal_references_tool ---\n",
        "\n",
        "print(\"--- Testing Internal PDF RAG Query Tool ---\")\n",
        "\n",
        "# Ensure RAG system seems ready and tool exists\n",
        "rag_system_ready = (\n",
        "    'query_internal_references_tool' in locals() and\n",
        "    pdf_rag_index is not None and\n",
        "    pdf_rag_embedder is not None and\n",
        "    pdf_rag_chunks and\n",
        "    pdf_rag_metadata\n",
        ")\n",
        "\n",
        "if rag_system_ready:\n",
        "    test_query = \"Occipital hypodensity, likely representing acute stroke.\" # Choose a term likely in neuro/radio PDFs\n",
        "    print(f\"Querying internal references for: '{test_query}' (top_k=2)\")\n",
        "\n",
        "    # Call the tool directly\n",
        "    rag_result_json_str = query_internal_references_tool(query=test_query, top_k=5)\n",
        "\n",
        "    print(f\"\\nRaw JSON Output from RAG tool:\\n{rag_result_json_str}\")\n",
        "\n",
        "    try:\n",
        "        rag_result = json.loads(rag_result_json_str)\n",
        "        if \"error\" in rag_result:\n",
        "            print(f\"\\n❌ Test Result (Error reported by tool): {rag_result['error']}\")\n",
        "        elif \"results\" in rag_result and isinstance(rag_result[\"results\"], list):\n",
        "            print(f\"\\n✅ Test Result (Success!): Found {len(rag_result['results'])} chunks.\")\n",
        "            # Store the global index of the first result for the next test\n",
        "            first_result_global_index_for_next_test = None\n",
        "            for i, chunk_info in enumerate(rag_result[\"results\"]):\n",
        "                print(f\"\\n--- Chunk {i+1} ---\")\n",
        "                print(f\"  Source PDF: {chunk_info.get('source_pdf_name', 'N/A')}\")\n",
        "                print(f\"  Global Index: {chunk_info.get('global_chunk_index', 'N/A')}\")\n",
        "                print(f\"  Index in Doc: {chunk_info.get('chunk_index_in_doc', 'N/A')}\")\n",
        "                print(f\"  Relevance Score: {chunk_info.get('relevance_score', 'N/A'):.4f}\" if chunk_info.get('relevance_score') is not None else \"  Relevance Score: N/A\")\n",
        "                print(f\"  Text Preview: {chunk_info.get('text', '')[:150]}...\")\n",
        "                # Save the index of the first valid result\n",
        "                if i == 0 and chunk_info.get('global_chunk_index', -1) != -1:\n",
        "                     first_result_global_index_for_next_test = chunk_info.get('global_chunk_index')\n",
        "\n",
        "            # Check if we stored an index for the neighbor test\n",
        "            if first_result_global_index_for_next_test is not None:\n",
        "                print(f\"\\n(Stored global_chunk_index {first_result_global_index_for_next_test} from the first result for the next test)\")\n",
        "            else:\n",
        "                print(\"\\n(Could not store a valid global_chunk_index from results for the next test)\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n❌ Test Error: RAG tool returned unexpected JSON structure.\")\n",
        "            print(f\"   Parsed JSON: {rag_result}\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"\\n❌ Test Error: RAG tool output was not valid JSON.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Test Error: An unexpected error occurred processing RAG result: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot run RAG query test: Tool not defined or RAG system not initialized.\")\n",
        "    print(\"   Please ensure PDF loading and RAG index building completed successfully in previous cells.\")\n",
        "    first_result_global_index_for_next_test = None # Ensure variable exists but is None\n",
        "\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U5K30bUOCQf",
        "outputId": "ac61f64b-1213-49ce-daf2-37440e42bb9e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Internal PDF RAG Query Tool ---\n",
            "Querying internal references for: 'Occipital hypodensity, likely representing acute stroke.' (top_k=2)\n",
            "Local PDF RAG Tool: Received query 'Occipital hypodensity, likely representing acute stroke.', top_k=5\n",
            "   ✅ Local PDF RAG Tool: Retrieved 5 structured items for 'Occipital hypodensity, likely representing acute stroke.'.\n",
            "\n",
            "Raw JSON Output from RAG tool:\n",
            "{\"query\": \"Occipital hypodensity, likely representing acute stroke.\", \"results\": [{\"text\": \"in conjunction with cortical/subcorti -\\ncal microhemorrhages, superficial siderosis, or chronic lobar hemorrhage, typical features of CAA. Distinguishing CAA-RI from ARIA-E solely by imaging is difficult, so medication history whether the patient is on anti-amyloid \\u03b2 immunotherapy is crucial (23, 35, 38).\\nISCHEMIC STROKE\\nBecause ARIA often presents with nonspecific neurological symptoms, it may be mistaken for ischemic strokes. Additionally, FLAIR hyperintensity in ARIA-E can resemble acute or subacute infarction. However, ARIA-E represents vasogenic edema and thus does not exhibit diffusion restriction on diffusion-weighted imaging (DWI). Consequently, including DWI se -\\nquence in MRI protocols for ARIA monitoring is advised to rule out the cytotoxic edema as-sociated with acute ischemic\", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 58, \"chunk_index_in_doc\": 37, \"relevance_score\": 0.9563440084457397}, {\"text\": \"IA-H\\nNumber of new micro-\\nhemorrhages\\n7 8 9\\n\\u22644 microhemorrhages 5\\u20139 microhemorrhages \\u226510 microhemorrhages\\nARIA are graded on the basis of treatment-emergent events. For ARIA-H, this count includes cumulative new microhemorrhages or regions of siderosis compared with the baseline, pretreatment examination.4\\nMRI images 1 to 5 and 7 to 9: data on file. MRI image 6 adapted with permission from Kate et al. (2018)11 CC BY 4.0: http://creativecommons.org/licenses/by/4.0/\\nMANAGING ARIA IN THE ED\\nIn the US, there are currently no evidence-based clinical guidelines for the management of ARIA in the ED5\\nCommunication about suspected ARIA with patient\\u2019s neurologist/physician is crucial6Management of ARIA and stroke are time-sensitive \\u2013 timely action and appropriate treatment are essential to ensure op\", \"source_pdf_name\": \"AD-M2400 ARIA in the ED infographic.pdf\", \"global_chunk_index\": 2, \"chunk_index_in_doc\": 2, \"relevance_score\": 0.9721435904502869}, {\"text\": \"esla.\\n\\u00a9 2025 Eisai Inc. All rights reserved. February 2025 AD-M2400This content is intended for healthcare professionals only for educational and informational purposes and does not substitute for sound medical judgment or clinical decision making in the context of medical treatment.THERE ARE TWO SUBTYPES OF ARIA\\nARIA-edema, effusion (ARIA-E): \\u25cf A buildup of fluid on the brain due to damage to the blood\\u2013brain barrier1 \\u25cf Brain swelling seen as hyperintensities on FLAIR MRI sequences2ARIA-hemosiderin, hemorrhage (ARIA-H):\\n\\u25cf Hemosiderin deposition in the parenchyma (microhemorrhages) or leptomeningeal/subpial space (superficial siderosis)1,2\\n\\u25cf Bleeds seen as hypointensities on T2* GRE or SWI MRI sequences2,3\\nHyperintense abnormalities on FLAIR sequencesHypointense abnormalities on T2* GRE seq\", \"source_pdf_name\": \"AD-M2400 ARIA in the ED infographic.pdf\", \"global_chunk_index\": 9, \"chunk_index_in_doc\": 9, \"relevance_score\": 0.9956786036491394}, {\"text\": \"resolves over a few weeks to months, ARIA-H (microhemorrhages and superficial siderosis) may persist or only partially fade (19, 30). Therefore, if ARIA-H is detect -\\ned, careful evaluation of the corresponding FLAIR images for subtle ARIA-E is warranted. Conversely, ARIA-E can occur without ARIA-H if red blood cell or their heme products have not yet leaked\\u2014or insufficient time has elapsed for the breakdown products to influence T2* Fig. 4. ARIA-H in a 58-year-old female patient with mild cognitive impairment, an ApoE \\u03b54 non-carrier, un -\\ndergoing lecanemab therapy.\\nA. On her baseline MRI, there are no microhemorrhages or superficial siderosis. B. On follow-up MRI after three months, SWI shows superficial siderosis at the right parietal sulci (arrow) with -\\nout symptoms, which is classifi\", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 53, \"chunk_index_in_doc\": 32, \"relevance_score\": 1.0071356296539307}, {\"text\": \"E \\u03b54 status and carefully scrutinizing baseline MRI for microhemorrhages or superficial siderosis can help predict the risk of ARIA. For those at elevated risk of ARIA, more frequent MRI monitor -\\ning is recommended, and physicians should thoroughly discuss these risks with patients and their caregivers.\\nCLINICAL SYMPTOMS OF ARIA\\nMost ARIA cases are asymptomatic. When there are symptoms, they are typically transient, mild, and reversible. Reported symptoms varied, ranging from nonspecific neurological com -\\nplaints (headache, nausea, vomiting) to confusion and gait or visual disturbances. In rare but in severe cases, cerebral edema, seizures, or even death were reported. Hospitalization or in -\\ntensive care may be required, and misdiagnosis as ischemic stroke is possible. Therefore, newly\", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 38, \"chunk_index_in_doc\": 17, \"relevance_score\": 1.0175708532333374}], \"message\": \"Successfully retrieved 5 relevant chunks from internal references.\"}\n",
            "\n",
            "✅ Test Result (Success!): Found 5 chunks.\n",
            "\n",
            "--- Chunk 1 ---\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 58\n",
            "  Index in Doc: 37\n",
            "  Relevance Score: 0.9563\n",
            "  Text Preview: in conjunction with cortical/subcorti -\n",
            "cal microhemorrhages, superficial siderosis, or chronic lobar hemorrhage, typical features of CAA. Distinguish...\n",
            "\n",
            "--- Chunk 2 ---\n",
            "  Source PDF: AD-M2400 ARIA in the ED infographic.pdf\n",
            "  Global Index: 2\n",
            "  Index in Doc: 2\n",
            "  Relevance Score: 0.9721\n",
            "  Text Preview: IA-H\n",
            "Number of new micro-\n",
            "hemorrhages\n",
            "7 8 9\n",
            "≤4 microhemorrhages 5–9 microhemorrhages ≥10 microhemorrhages\n",
            "ARIA are graded on the basis of treatment-em...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "  Source PDF: AD-M2400 ARIA in the ED infographic.pdf\n",
            "  Global Index: 9\n",
            "  Index in Doc: 9\n",
            "  Relevance Score: 0.9957\n",
            "  Text Preview: esla.\n",
            "© 2025 Eisai Inc. All rights reserved. February 2025 AD-M2400This content is intended for healthcare professionals only for educational and info...\n",
            "\n",
            "--- Chunk 4 ---\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 53\n",
            "  Index in Doc: 32\n",
            "  Relevance Score: 1.0071\n",
            "  Text Preview: resolves over a few weeks to months, ARIA-H (microhemorrhages and superficial siderosis) may persist or only partially fade (19, 30). Therefore, if AR...\n",
            "\n",
            "--- Chunk 5 ---\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 38\n",
            "  Index in Doc: 17\n",
            "  Relevance Score: 1.0176\n",
            "  Text Preview: E ε4 status and carefully scrutinizing baseline MRI for microhemorrhages or superficial siderosis can help predict the risk of ARIA. For those at elev...\n",
            "\n",
            "(Stored global_chunk_index 58 from the first result for the next test)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Retrieve Neighboring Chunks Tool (retrieve_neighboring_chunks_tool)\n",
        "This tool is specifically designed to support the InternalReferenceExpertAgent (our RAG-focused CodeAgent). After the agent uses query_internal_references_tool to find an initial set of relevant text chunks, it might want to see more context around a particularly promising chunk.\n",
        "\n",
        "The retrieve_neighboring_chunks_tool takes:\n",
        "\n",
        "- target_global_chunk_index: The global index of the chunk for which context is desired (this index is provided in the output of query_internal_references_tool).\n",
        "- num_before: How many chunks immediately preceding the target chunk to retrieve.\n",
        "- num_after: How many chunks immediately succeeding the target chunk to retrieve.\n",
        "\n",
        "It's careful to only retrieve neighbors that belong to the same original PDF document as the target chunk, preventing irrelevant context from other documents. The output is a JSON string containing a list of these context chunks (including the target chunk itself), each tagged with its type (e.g., 'target', 'before_1', 'after_1') and its metadata."
      ],
      "metadata": {
        "id": "i8m4qzUQNHUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "@tool\n",
        "def retrieve_neighboring_chunks_tool(target_global_chunk_index: int, num_before: int = 1, num_after: int = 1) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves text chunks immediately preceding and succeeding a specified target chunk\n",
        "    from the internal PDF knowledge base. Ensures that all retrieved neighboring chunks\n",
        "    belong to the SAME SOURCE DOCUMENT as the target chunk. This tool is vital for\n",
        "    obtaining wider contextual understanding around an initially retrieved piece of information.\n",
        "\n",
        "    Args:\n",
        "        target_global_chunk_index (int): The 'global_chunk_index' of the target chunk.\n",
        "                                         This index is obtained from the output of the\n",
        "                                         `query_internal_references_tool`.\n",
        "        num_before (int): The number of chunks to retrieve immediately before the target chunk.\n",
        "                          Defaults to 1. Allowed range: 0 to 3.\n",
        "        num_after (int): The number of chunks to retrieve immediately after the target chunk.\n",
        "                         Defaults to 1. Allowed range: 0 to 3.\n",
        "\n",
        "    Returns:\n",
        "        str: A JSON string.\n",
        "             If successful, the JSON string contains an object with a \"results\" key. The value\n",
        "             of \"results\" is a list of context chunk objects. Each object includes 'type'\n",
        "             (e.g., 'target', 'before_1', 'after_1'), 'text', 'source_pdf_name',\n",
        "             'global_chunk_index', and 'chunk_index_in_doc'. The list is ordered:\n",
        "             [before_n, ..., before_1, target, after_1, ..., after_n].\n",
        "             If an error occurs (e.g., index out of bounds, target chunk metadata issues),\n",
        "             the JSON string will contain an object with an \"error\" key and a descriptive message.\n",
        "             A \"warning\" key might be present if only the target chunk is returned despite\n",
        "             requesting neighbors (e.g., if at document boundaries).\n",
        "    \"\"\"\n",
        "    global pdf_rag_chunks, pdf_rag_metadata # Access globally stored RAG data\n",
        "\n",
        "    print(f\"Neighbor Chunks Tool: Request for target_global_idx={target_global_chunk_index}, num_before={num_before}, num_after={num_after}\")\n",
        "\n",
        "    # Validate RAG system readiness and input parameters\n",
        "    if not all([pdf_rag_chunks, pdf_rag_metadata]) or len(pdf_rag_chunks) != len(pdf_rag_metadata):\n",
        "        print(\"   ❌ Error: PDF RAG system (chunks/metadata) is not properly initialized or has data inconsistency.\")\n",
        "        return json.dumps({\"error\": \"PDF RAG system (chunks/metadata) is not properly initialized or has data inconsistency.\"})\n",
        "\n",
        "    if not (isinstance(target_global_chunk_index, int) and 0 <= target_global_chunk_index < len(pdf_rag_chunks)):\n",
        "        print(f\"   ❌ Error: Invalid target_global_chunk_index: {target_global_chunk_index}. Must be an integer within bounds (0-{len(pdf_rag_chunks)-1}).\")\n",
        "        return json.dumps({\"error\": f\"Invalid target_global_chunk_index: {target_global_chunk_index}. Must be an integer within bounds (0-{len(pdf_rag_chunks)-1}).\"})\n",
        "\n",
        "    # Sanitize num_before and num_after to be within reasonable limits (e.g., 0-3)\n",
        "    num_before = min(max(0, int(num_before)), 3)\n",
        "    num_after = min(max(0, int(num_after)), 3)\n",
        "\n",
        "    try:\n",
        "        target_chunk_meta = pdf_rag_metadata[target_global_chunk_index]\n",
        "        target_chunk_text = pdf_rag_chunks[target_global_chunk_index]\n",
        "        target_source_pdf = target_chunk_meta.get('source_pdf_name') # Get the source PDF of the target chunk\n",
        "\n",
        "        if target_source_pdf is None: # Should not happen if metadata is built correctly\n",
        "            print(f\"   ❌ Error: Metadata for target chunk (global_idx {target_global_chunk_index}) is missing 'source_pdf_name'.\")\n",
        "            return json.dumps({\"error\": f\"Metadata for target chunk (global_idx {target_global_chunk_index}) is missing 'source_pdf_name'.\"})\n",
        "\n",
        "        # Initialize list to store all context chunks, starting with the target\n",
        "        context_chunks_list = [{\n",
        "            \"type\": \"target\", # Identifies this as the original target chunk\n",
        "            \"text\": target_chunk_text,\n",
        "            \"source_pdf_name\": target_source_pdf,\n",
        "            \"global_chunk_index\": target_global_chunk_index,\n",
        "            \"chunk_index_in_doc\": target_chunk_meta.get('chunk_index_in_doc', -1)\n",
        "        }]\n",
        "\n",
        "        # Retrieve preceding chunks from the same document\n",
        "        for i in range(1, num_before + 1):\n",
        "            prev_global_idx = target_global_chunk_index - i\n",
        "            if prev_global_idx >= 0: # Check if index is within global bounds\n",
        "                prev_meta = pdf_rag_metadata[prev_global_idx]\n",
        "                # CRITICAL: Ensure the preceding chunk is from the SAME source PDF\n",
        "                if prev_meta.get('source_pdf_name') == target_source_pdf:\n",
        "                    context_chunks_list.insert(0, { # Insert at the beginning to maintain natural reading order\n",
        "                        \"type\": f\"before_{i}\",\n",
        "                        \"text\": pdf_rag_chunks[prev_global_idx],\n",
        "                        \"source_pdf_name\": target_source_pdf,\n",
        "                        \"global_chunk_index\": prev_global_idx,\n",
        "                        \"chunk_index_in_doc\": prev_meta.get('chunk_index_in_doc', -1)\n",
        "                    })\n",
        "                else: # Reached the boundary of a different document\n",
        "                    print(f\"   ℹ️ Boundary: Preceding chunk (global_idx {prev_global_idx}) is from a different document. Stopping 'before' search.\")\n",
        "                    break\n",
        "            else: # Reached the beginning of the global chunk list\n",
        "                break\n",
        "\n",
        "        # Retrieve succeeding chunks from the same document\n",
        "        for i in range(1, num_after + 1):\n",
        "            next_global_idx = target_global_chunk_index + i\n",
        "            if next_global_idx < len(pdf_rag_chunks): # Check if index is within global bounds\n",
        "                next_meta = pdf_rag_metadata[next_global_idx]\n",
        "                # CRITICAL: Ensure the succeeding chunk is from the SAME source PDF\n",
        "                if next_meta.get('source_pdf_name') == target_source_pdf:\n",
        "                    context_chunks_list.append({\n",
        "                        \"type\": f\"after_{i}\",\n",
        "                        \"text\": pdf_rag_chunks[next_global_idx],\n",
        "                        \"source_pdf_name\": target_source_pdf,\n",
        "                        \"global_chunk_index\": next_global_idx,\n",
        "                        \"chunk_index_in_doc\": next_meta.get('chunk_index_in_doc', -1)\n",
        "                    })\n",
        "                else: # Reached the boundary of a different document\n",
        "                    print(f\"   ℹ️ Boundary: Succeeding chunk (global_idx {next_global_idx}) is from a different document. Stopping 'after' search.\")\n",
        "                    break\n",
        "            else: # Reached the end of the global chunk list\n",
        "                break\n",
        "\n",
        "        output_payload = {\"results\": context_chunks_list}\n",
        "        if len(context_chunks_list) == 1 and (num_before > 0 or num_after > 0) :\n",
        "            # Only target chunk was added, but neighbors were requested\n",
        "            output_payload[\"warning\"] = (\"Only the target chunk itself was retrieved; no valid neighbors found \"\n",
        "                                         \"within the same document for the requested range (e.g., target is at document start/end).\")\n",
        "\n",
        "        print(f\"   ✅ Neighbor Chunks Tool: Retrieved {len(context_chunks_list)} total context chunks for target_global_idx {target_global_chunk_index}.\")\n",
        "        return json.dumps(output_payload)\n",
        "\n",
        "    except IndexError: # Should be rare if bounds are checked, but good for safety\n",
        "        print(f\"   ❌ Error: Index out of bounds while accessing RAG chunks/metadata for target_global_idx {target_global_chunk_index}.\")\n",
        "        return json.dumps({\"error\": f\"Index error while accessing chunks/metadata for target_global_idx {target_global_chunk_index}. This might indicate RAG system data inconsistency.\"})\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Neighbor Chunks Tool: Unexpected error for target_global_idx {target_global_chunk_index}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return json.dumps({\"error\": f\"An unexpected error occurred in retrieve_neighboring_chunks_tool: {str(e)}\"})"
      ],
      "metadata": {
        "id": "HQuKHvV9NX9s",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Test: retrieve_neighboring_chunks_tool ---\n",
        "\n",
        "print(\"--- Testing Neighboring Chunks Tool ---\")\n",
        "\n",
        "# Check if tool exists and if we have a valid target index from the previous test\n",
        "neighbor_tool_ready = (\n",
        "    'retrieve_neighboring_chunks_tool' in locals() and\n",
        "    'first_result_global_index_for_next_test' in locals() and\n",
        "    first_result_global_index_for_next_test is not None and\n",
        "    isinstance(first_result_global_index_for_next_test, int) and\n",
        "    pdf_rag_chunks and # Check RAG system still seems loaded\n",
        "    pdf_rag_metadata\n",
        ")\n",
        "\n",
        "if neighbor_tool_ready:\n",
        "    target_idx = first_result_global_index_for_next_test\n",
        "    num_b = 1\n",
        "    num_a = 1\n",
        "    print(f\"Attempting to retrieve neighbors for target global_chunk_index: {target_idx} (before={num_b}, after={num_a})\")\n",
        "\n",
        "    # Call the tool directly\n",
        "    neighbor_result_json_str = retrieve_neighboring_chunks_tool(\n",
        "        target_global_chunk_index=target_idx,\n",
        "        num_before=num_b,\n",
        "        num_after=num_a\n",
        "    )\n",
        "\n",
        "    print(f\"\\nRaw JSON Output from Neighbor tool:\\n{neighbor_result_json_str}\")\n",
        "\n",
        "    try:\n",
        "        neighbor_result = json.loads(neighbor_result_json_str)\n",
        "        if \"error\" in neighbor_result:\n",
        "            print(f\"\\n❌ Test Result (Error reported by tool): {neighbor_result['error']}\")\n",
        "        elif \"results\" in neighbor_result and isinstance(neighbor_result[\"results\"], list):\n",
        "            print(f\"\\n✅ Test Result (Success!): Retrieved {len(neighbor_result['results'])} context chunks (target + neighbors).\")\n",
        "            if \"warning\" in neighbor_result:\n",
        "                print(f\"   Note: Tool issued a warning: {neighbor_result['warning']}\")\n",
        "\n",
        "            for chunk_info in neighbor_result[\"results\"]:\n",
        "                 print(f\"\\n--- Context Chunk ---\")\n",
        "                 print(f\"  Type: {chunk_info.get('type', 'N/A')}\")\n",
        "                 print(f\"  Source PDF: {chunk_info.get('source_pdf_name', 'N/A')}\")\n",
        "                 print(f\"  Global Index: {chunk_info.get('global_chunk_index', 'N/A')}\")\n",
        "                 print(f\"  Index in Doc: {chunk_info.get('chunk_index_in_doc', 'N/A')}\")\n",
        "                 print(f\"  Text Preview: {chunk_info.get('text', '')[:150]}...\")\n",
        "        else:\n",
        "            print(\"\\n❌ Test Error: Neighbor tool returned unexpected JSON structure.\")\n",
        "            print(f\"   Parsed JSON: {neighbor_result}\")\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"\\n❌ Test Error: Neighbor tool output was not valid JSON.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Test Error: An unexpected error occurred processing neighbor result: {e}\")\n",
        "\n",
        "elif 'retrieve_neighboring_chunks_tool' not in locals():\n",
        "     print(\"❌ Cannot run neighbor test: `retrieve_neighboring_chunks_tool` function not defined.\")\n",
        "elif 'first_result_global_index_for_next_test' not in locals() or first_result_global_index_for_next_test is None:\n",
        "     print(\"❌ Cannot run neighbor test: No valid 'global_chunk_index' obtained from the previous RAG query test.\")\n",
        "     print(\"   Please ensure the RAG query test ran successfully and found at least one result.\")\n",
        "else:\n",
        "     print(\"❌ Cannot run neighbor test: RAG system (chunks/metadata) seems uninitialized.\")\n",
        "\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8dM3yEPOGU4",
        "outputId": "afd974f9-8abe-40fc-feea-d6826aeff645",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Neighboring Chunks Tool ---\n",
            "Attempting to retrieve neighbors for target global_chunk_index: 48 (before=1, after=1)\n",
            "Neighbor Chunks Tool: Request for target_global_idx=48, num_before=1, num_after=1\n",
            "   ✅ Neighbor Chunks Tool: Retrieved 3 total context chunks for target_global_idx 48.\n",
            "\n",
            "Raw JSON Output from Neighbor tool:\n",
            "{\"results\": [{\"type\": \"before_1\", \"text\": \"s ARIA-E in, whereas ARIA-E in the setting of an -\\nti-amyloid \\u03b2 immunotherapy is viewed as an iatrogenic CAA-RI or CAA-RI\\u2013like syndrome. So -\\nlopova et al. (34) reported autopsy findings of an acute arteritis pattern resembling severe CAA-RI in a fatal ARIA case under lecanemab treatment, including widespread inflammation with macrophages and activated microglia, along with arteriol degeneration (25, 34). Unlike drug-induced ARIA, spontaneous CAA-RI is an autoimmune process that responds to immu -\\nnosuppressive therapy and corticosteroids (35). On contrast enhanced MRI, involving the me -\\nning\\nes or brain parenchyma may be enhancing (36, 37) in conjunction with cortical/subcorti -\\ncal microhemorrhages, superficial siderosis, or chronic lobar hemorrhage, typical features of CAA. Distinguish\", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 47, \"chunk_index_in_doc\": 36}, {\"type\": \"target\", \"text\": \"in conjunction with cortical/subcorti -\\ncal microhemorrhages, superficial siderosis, or chronic lobar hemorrhage, typical features of CAA. Distinguishing CAA-RI from ARIA-E solely by imaging is difficult, so medication history whether the patient is on anti-amyloid \\u03b2 immunotherapy is crucial (23, 35, 38).\\nISCHEMIC STROKE\\nBecause ARIA often presents with nonspecific neurological symptoms, it may be mistaken for ischemic strokes. Additionally, FLAIR hyperintensity in ARIA-E can resemble acute or subacute infarction. However, ARIA-E represents vasogenic edema and thus does not exhibit diffusion restriction on diffusion-weighted imaging (DWI). Consequently, including DWI se -\\nquence in MRI protocols for ARIA monitoring is advised to rule out the cytotoxic edema as-sociated with acute ischemic \", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 48, \"chunk_index_in_doc\": 37}, {\"type\": \"after_1\", \"text\": \"nsequently, including DWI se -\\nquence in MRI protocols for ARIA monitoring is advised to rule out the cytotoxic edema as-sociated with acute ischemic stroke (23, 26).\\nPOSTERIOR REVERSIBLE ENCEPHALOPATHY SYNDROME (PRES)\\nBoth ARIA-E and posterior reversible encephalopathy syndrome (PRES) frequently involve the occipital lobe and exhibit similar FLAIR hyperintensities, and both are generally revers-ible. PRES is associated with identifiable risk factors such as uncontrolled hypertension, cy -\\ntotoxic agents, preeclampsia, sepsis, renal disease, or autoimmune disorders. In contrast, ARIA arises specifically in the context of anti-amyloid \\u03b2 immunotherapy (22, 25, 34). Hence, integrating relevant clinical information, including underlying risk factors, is essential for accurate diagnosis.\\nSUBARA\", \"source_pdf_name\": \"jksr-86-17-s001.pdf\", \"global_chunk_index\": 49, \"chunk_index_in_doc\": 38}]}\n",
            "\n",
            "✅ Test Result (Success!): Retrieved 3 context chunks (target + neighbors).\n",
            "\n",
            "--- Context Chunk ---\n",
            "  Type: before_1\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 47\n",
            "  Index in Doc: 36\n",
            "  Text Preview: s ARIA-E in, whereas ARIA-E in the setting of an -\n",
            "ti-amyloid β immunotherapy is viewed as an iatrogenic CAA-RI or CAA-RI–like syndrome. So -\n",
            "lopova e...\n",
            "\n",
            "--- Context Chunk ---\n",
            "  Type: target\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 48\n",
            "  Index in Doc: 37\n",
            "  Text Preview: in conjunction with cortical/subcorti -\n",
            "cal microhemorrhages, superficial siderosis, or chronic lobar hemorrhage, typical features of CAA. Distinguish...\n",
            "\n",
            "--- Context Chunk ---\n",
            "  Type: after_1\n",
            "  Source PDF: jksr-86-17-s001.pdf\n",
            "  Global Index: 49\n",
            "  Index in Doc: 38\n",
            "  Text Preview: nsequently, including DWI se -\n",
            "quence in MRI protocols for ARIA monitoring is advised to rule out the cytotoxic edema as-sociated with acute ischemic ...\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Web Search Tool (DuckDuckGoSearchTool)\n",
        "We also need a general web search capability, primarily for the RadiopaediaExpertAgent to find the correct Radiopaedia article URLs based on a diagnosis term. SmolAgents provides a ready-made tool using DuckDuckGo for this that can be passed to agents as a base tool (so, no need for custom definition by us), but if you want to see how it works, it is like the following code snippet:"
      ],
      "metadata": {
        "id": "cO9OBXdzO_qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 3, ADD this cell:\n",
        "\n",
        "from smolagents import DuckDuckGoSearchTool\n",
        "\n",
        "web_search_tool = None # Initialize to None\n",
        "try:\n",
        "    # Instantiate the pre-built tool\n",
        "    web_search_tool = DuckDuckGoSearchTool()\n",
        "    print(\"✅ WebSearchTool instantiated successfully.\")\n",
        "    # Display its description so the learner sees what the agent knows about it\n",
        "    print(f\"   Tool Description: {web_search_tool.description}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error instantiating WebSearchTool: {e}\")\n",
        "    print(\"   Web search capabilities will be unavailable if this failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_LuthG9PGn_",
        "outputId": "42b24e5e-2f57-406f-cb0f-86f14a1c7883",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ WebSearchTool instantiated successfully.\n",
            "   Tool Description: Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Code Cell 4: Testing DuckDuckGoSearchTool (NEW TEST CELL)\n",
        "\n",
        "print(\"--- Testing DuckDuckGo Search Tool ---\")\n",
        "\n",
        "# Check if the tool was instantiated successfully\n",
        "if web_search_tool is not None and 'web_search_tool' in locals():\n",
        "    # Example query: Find the radiopaedia page for Multiple Sclerosis\n",
        "    test_search_query = \"stroke site:radiopaedia.org\"\n",
        "    print(f\"Performing web search for: '{test_search_query}'\")\n",
        "\n",
        "    try:\n",
        "        # Call the tool's forward method (or call the instance directly)\n",
        "        # SmolAgent tools can often be called directly as functions\n",
        "        search_results_str = web_search_tool(query=test_search_query)\n",
        "\n",
        "        print(\"\\n✅ Web Search Result (Success!):\")\n",
        "        # The tool typically returns a formatted string of results\n",
        "        print(search_results_str)\n",
        "        print(\"\\n(Observe if the top result(s) point to the correct Radiopaedia URL)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Test Error: An unexpected error occurred during web search: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot run web search test: `web_search_tool` was not instantiated successfully.\")\n",
        "\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyoxZFUQPYIt",
        "outputId": "fd405237-555d-404a-9088-f57998feb9b3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing DuckDuckGo Search Tool ---\n",
            "Performing web search for: 'stroke site:radiopaedia.org'\n",
            "\n",
            "✅ Web Search Result (Success!):\n",
            "## Search Results\n",
            "\n",
            "[Ischemic stroke | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/ischemic-stroke-2?lang=us)\n",
            "Terminology. The term \"stroke\" is a clinical determination, whereas \"infarction\" is fundamentally a pathologic term 1.. Bridging these terms, ischemic stroke is the subtype of stroke that requires both a clinical neurologic deficit and evidence of CNS infarction (cell death attributable to ischemia). The evidence of infarction may be based on imaging, pathology, and/or persistent neurologic ...\n",
            "\n",
            "[Stroke | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/stroke)\n",
            "A stroke is a clinical diagnosis that refers to a sudden onset focal neurological deficit of presumed vascular origin.. Stroke is generally divided into two broad categories 1,2:. ischemic stroke (87%); hemorrhagic stroke (13%); Terminology. The term \"stroke\" is ambiguous and care must be taken to ensure that precise terminology is used.\n",
            "\n",
            "[Stroke | Radiology Reference Article | Radiopaedia.org](https://radiopaedia.org/articles/stroke?lang=gb)\n",
            "A stroke is a clinical diagnosis that refers to a sudden onset focal neurological deficit of presumed vascular origin.. Stroke is generally divided into two broad categories 1,2:. ischaemic stroke (87%); haemorrhagic stroke (13%); Terminology. The term \"stroke\" is ambiguous and care must be taken to ensure that precise terminology is used.\n",
            "\n",
            "[Ischemic stroke (summary) | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/ischaemic-stroke-summary)\n",
            "This is a summary article; read more in our article on ischemic stroke. Summary. anatomy. cerebral vascular territories. epidemiology. common, accounts for 80% of stroke overall 1. the other 20% is hemorrhagic stroke. leading cause of disability. third highest cause of mortality in the UK 2,3. presentation\n",
            "\n",
            "[Stroke protocol (MRI) | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/stroke-protocol-mri)\n",
            "MRI protocol for stroke assessment is a group of MRI sequences put together to best approach brain ischemia.. CT is still the choice as the first imaging modality in acute stroke institutional protocols, not only because the availability and the easy and fast access to a CT scanner, but also due the better sensitivity for intracerebral hemorrhage (ICH) diagnosis 1.\n",
            "\n",
            "[Cerebral venous infarction | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/cerebral-venous-infarction)\n",
            "Cerebral venous infarction is an uncommon form of stroke, and is most commonly secondary to cerebral venous thrombosis and frequently manifests with hemorrhage. It should be considered in infarcts (with or without hemorrhage) which do not correspond to a typical arterial territory 1. On this page: Article:\n",
            "\n",
            "[Posterior cerebral artery (PCA) infarct - Radiopaedia.org](https://radiopaedia.org/articles/posterior-cerebral-artery-pca-infarct)\n",
            "Epidemiology. Posterior cerebral artery strokes are believed to comprise approximately 5-10% of ischemic strokes 6.. Clinical presentation. Symptoms of posterior cerebral artery stroke include contralateral homonymous hemianopia (due to occipital infarction), hemisensory loss (due to thalamic infarction) and hemi-body pain (usually burning in nature and due to thalamic infarction) 3.\n",
            "\n",
            "[Stroke volume | Radiology Reference Article - Radiopaedia.org](https://radiopaedia.org/articles/stroke-volume?lang=us)\n",
            "The stroke volume is another integral parameter used for the assessment of cardiac function, the calculation of ejection fraction and cardiac output. Measurement Ultrasound Echocardiography. Stroke volume may be derived using echocardiography from measurements of the area of the left ventricular outflow tract (LVOT) and the stroke distance.\n",
            "\n",
            "[Anterior inferior cerebellar artery (AICA) infarct](https://radiopaedia.org/articles/anterior-inferior-cerebellar-artery-aica-infarct-1?lang=us)\n",
            "Epidemiology. AICA territory infarcts are rare, comprising ~1% of ischemic strokes 2.. Clinical presentation. Vertigo (can be central or peripheral due to the arterial supply) is the most common symptom associated with an AICA infarct, however, it is normally associated with neurological signs and symptoms such as ipsilateral hypoacusis (hearing loss), facial weakness, facial sensory loss ...\n",
            "\n",
            "[TOAST classification in acute ischemic stroke](https://radiopaedia.org/articles/toast-classification-in-acute-ischemic-stroke-1?lang=us)\n",
            "The TOAST (Trial of ORG 10172 in Acute Stroke Treatment) classification denotes five etiologies of ischemic stroke. large-artery atherosclerosis. cardioembolism. small-vessel occlusion . stroke of other determined etiology. stroke of undetermined etiology. It is thought to carry good interobserver agreement 2.\n",
            "\n",
            "(Observe if the top result(s) point to the correct Radiopaedia URL)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4. Agent Setup Using SmolAgents\n",
        "\n",
        "With our specialized tools defined, we now construct the AI agents that will use them. This section details the setup of our three-agent system, designed for a sophisticated radiology report analysis workflow:\n",
        "\n",
        "1. **LLM Configuration**: Setting up the InferenceClientModel instances that power the agents.\n",
        "2. **Initial Information Extraction**: Defining the extract_impression_and_findings_with_groq function for pre-processing the user's transcription.\n",
        "3. **Custom Agent Instructions**: Defining the detailed instruction strings that will be appended to each agent's default system prompt to guide their specific roles and workflows.\n",
        "4. **Expert Agents**:\n",
        "  - **RadiopaediaExpertAgent** (CodeAgent): Takes a primary diagnosis, uses web_search_tool to find the Radiopaedia URL, uses radiopaedia_content_extraction_tool to get content, and returns a concise summary.\n",
        "  - **InternalReferenceExpertAgent** (CodeAgent): Takes imaging findings, uses query_internal_references_tool and retrieve_neighboring_chunks_tool to research differential diagnoses (Ddx) within local PDFs, and returns structured JSON results.\n",
        "5. **Orchestrator Agent** (RadiologyReportAnalyzer - CodeAgent): The central coordinator, directing the expert agents and synthesizing their findings into final differential diagnosis suggestions for the user.\n",
        "\n",
        "We will initialize each agent and then customize its behavior by appending our specific instructions to its prompt_templates[\"system_prompt\"]."
      ],
      "metadata": {
        "id": "Eoo6sbiUD3TM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1: Define LLM Models for Agents\n",
        "\n",
        "Each agent requires an LLM \"brain\". We use InferenceClientModel from SmolAgents to connect to suitable models (e.g., via Hugging Face Inference API or partners). We'll configure models for the orchestrator (needs strong reasoning/coding), the Internal Reference code agent (also needs coding ability), and the Radiopaedia tool-calling agent.\n"
      ],
      "metadata": {
        "id": "JEznV8J2Q4hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 4\n",
        "\n",
        "# --- Define LLM Models for Agents ---\n",
        "\n",
        "# Ensure HF_TOKEN is available and login was successful from Section 1\n",
        "if not HF_TOKEN or not HfFolder.get_token():\n",
        "     raise ValueError(\n",
        "         \"❌ HF_TOKEN is not set or Hugging Face login failed in Section 1. \"\n",
        "         \"Cannot initialize InferenceClientModel. Please review Section 1 setup.\"\n",
        "     )\n",
        "\n",
        "# --- Configuration for LLM Providers ---\n",
        "# If needed, specify provider details here (e.g., for TogetherAI, FireworksAI)\n",
        "LLM_PROVIDER_DETAILS = {}\n",
        "# Example: LLM_PROVIDER_DETAILS = {\"provider\": \"together\"}\n",
        "\n",
        "# --- Model Selection ---\n",
        "# Orchestrator (CodeAgent): Needs strong reasoning, planning, code generation\n",
        "# ORCHESTRATOR_MODEL_ID = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
        "ORCHESTRATOR_MODEL_ID = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
        "\n",
        "# Internal Reference Expert (CodeAgent): Also needs good reasoning/code generation\n",
        "INTERNAL_EXPERT_CODE_AGENT_MODEL_ID = \"Qwen/Qwen2.5-Coder-32B-Instruct\" # Or use 70B if 8B struggles\n",
        "# INTERNAL_EXPERT_CODE_AGENT_MODEL_ID = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
        "# Radiopaedia Expert (CodeAgent): Task is more focused, can use a smaller model\n",
        "RADIOPEDIA_AGENT_MODEL_ID = \"Qwen/Qwen2.5-Coder-32B-Instruct\"\n",
        "# RADIOPEDIA_AGENT_MODEL_ID = \"meta-llama/Llama-3.1-70B-Instruct\"\n",
        "print(f\"Attempting to use ORCHESTRATOR_MODEL_ID: {ORCHESTRATOR_MODEL_ID}\")\n",
        "print(f\"Attempting to use INTERNAL_EXPERT_CODE_AGENT_MODEL_ID: {INTERNAL_EXPERT_CODE_AGENT_MODEL_ID}\")\n",
        "print(f\"Attempting to use RADIOPEDIA_AGENT_MODEL_ID (for Radiopaedia Expert): {RADIOPEDIA_AGENT_MODEL_ID}\")\n",
        "\n",
        "orchestrator_llm_model = None\n",
        "internal_expert_llm_model = None\n",
        "radiopedia_scraping_model = None # For Radiopaedia Expert\n",
        "\n",
        "try:\n",
        "    print(f\"\\nInitializing Orchestrator LLM: {ORCHESTRATOR_MODEL_ID}...\")\n",
        "    orchestrator_llm_model = InferenceClientModel(\n",
        "        model_id=ORCHESTRATOR_MODEL_ID,\n",
        "        token=HF_TOKEN,\n",
        "        max_tokens=4096,  # Ample for complex logic and JSON output\n",
        "        temperature=0.1,      # Low temp for deterministic code/planning\n",
        "        **LLM_PROVIDER_DETAILS\n",
        "    )\n",
        "    print(f\"✅ Orchestrator LLM ({ORCHESTRATOR_MODEL_ID}) initialized.\")\n",
        "\n",
        "    print(f\"\\nInitializing Internal Reference Expert LLM: {INTERNAL_EXPERT_CODE_AGENT_MODEL_ID}...\")\n",
        "    internal_expert_llm_model = InferenceClientModel(\n",
        "        model_id=INTERNAL_EXPERT_CODE_AGENT_MODEL_ID,\n",
        "        token=HF_TOKEN,\n",
        "        max_tokens=4096, # Needs space for code generation and reasoning\n",
        "        temperature=0.1,     # Low temp for reliable code generation\n",
        "        **LLM_PROVIDER_DETAILS\n",
        "    )\n",
        "    print(f\"✅ Internal Reference Expert LLM ({INTERNAL_EXPERT_CODE_AGENT_MODEL_ID}) initialized.\")\n",
        "\n",
        "    print(f\"\\nInitializing Radiopaedia Expert LLM: {RADIOPEDIA_AGENT_MODEL_ID}...\")\n",
        "    radiopedia_scraping_model = InferenceClientModel(\n",
        "        model_id=RADIOPEDIA_AGENT_MODEL_ID,\n",
        "        token=HF_TOKEN,\n",
        "        max_tokens=10000, # Room for reasoning and summarizing\n",
        "        temperature=0.2,     # Slightly higher temp might help summarization creativity\n",
        "        **LLM_PROVIDER_DETAILS\n",
        "    )\n",
        "    print(f\"✅ Radiopaedia Expert LLM ({RADIOPEDIA_AGENT_MODEL_ID}) initialized.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error initializing one or more InferenceClientModels: {e}\")\n",
        "    print(\"   Troubleshooting tips:\")\n",
        "    print(\"   - Verify your HF_TOKEN in Section 1.\")\n",
        "    print(\"   - Check the model IDs are valid and accessible via your token/provider.\")\n",
        "    print(\"   - Consider trying smaller models (e.g., 8B versions) if resource limits are suspected.\")\n",
        "    # Ensure models are None if init failed\n",
        "    if 'orchestrator_llm_model' not in locals() or orchestrator_llm_model is None: orchestrator_llm_model = None\n",
        "    if 'internal_expert_llm_model' not in locals() or internal_expert_llm_model is None: internal_expert_llm_model = None\n",
        "    if 'radiopedia_scraping_model' not in locals() or radiopedia_scraping_model is None: radiopedia_scraping_model = None\n",
        "    print(\"\\nContinuing setup, but agent functionality may be affected if LLMs failed.\")"
      ],
      "metadata": {
        "id": "y1LLF9PHx_CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755ee3b2-f269-4ca5-caf2-ea8f10909823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to use ORCHESTRATOR_MODEL_ID: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "Attempting to use INTERNAL_EXPERT_CODE_AGENT_MODEL_ID: Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "Attempting to use RADIOPEDIA_AGENT_MODEL_ID (for Radiopaedia Expert): Qwen/Qwen2.5-Coder-32B-Instruct\n",
            "\n",
            "Initializing Orchestrator LLM: Qwen/Qwen2.5-Coder-32B-Instruct...\n",
            "✅ Orchestrator LLM (Qwen/Qwen2.5-Coder-32B-Instruct) initialized.\n",
            "\n",
            "Initializing Internal Reference Expert LLM: Qwen/Qwen2.5-Coder-32B-Instruct...\n",
            "✅ Internal Reference Expert LLM (Qwen/Qwen2.5-Coder-32B-Instruct) initialized.\n",
            "\n",
            "Initializing Radiopaedia Expert LLM: Qwen/Qwen2.5-Coder-32B-Instruct...\n",
            "✅ Radiopaedia Expert LLM (Qwen/Qwen2.5-Coder-32B-Instruct) initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Define Initial Diagnosis and Findings Extraction Function\n",
        "This function uses a fast external LLM call (Groq) to pre-process the user's transcript, separating the likely primary diagnosis from the listed imaging findings. This structured data simplifies the input for our main Orchestrator agent."
      ],
      "metadata": {
        "id": "_bhSkYYlRAc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 4\n",
        "\n",
        "# (Make sure 'json' is imported, typically done in Section 1)\n",
        "# import json\n",
        "\n",
        "def extract_impression_and_findings_with_groq(report_text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Uses a Groq LLM to extract a primary impression and a list of key imaging\n",
        "    findings from a radiology report, returning them in a dictionary.\n",
        "\n",
        "    Args:\n",
        "        report_text (str): The transcribed radiology report.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with keys \"primary_diagnosis\" (str | None) and\n",
        "              \"imaging_findings\" (list[str]). Returns default with None/empty list\n",
        "              on error or if items are not found.\n",
        "    \"\"\"\n",
        "    global groq_client # Use the client initialized in Section 1\n",
        "    default_return = {\"primary_diagnosis\": None, \"imaging_findings\": []}\n",
        "    if not groq_client:\n",
        "        print(\"⚠️ Groq client not initialized (check Section 1 setup). Cannot extract diagnosis/findings via Groq.\")\n",
        "        return default_return\n",
        "    if not report_text or not report_text.strip():\n",
        "        print(\"⚠️ No report text provided to extract_impression_and_findings_with_groq.\")\n",
        "        return default_return\n",
        "\n",
        "    print(\"Attempting to extract primary diagnosis and imaging findings using Groq LLM...\")\n",
        "    try:\n",
        "        # Ensure model name is current on Groq\n",
        "        groq_model_name = \"llama-3.3-70b-versatile\" # Or \"llama3-70b-8192\", etc.\n",
        "\n",
        "        chat_completion = groq_client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": (\n",
        "                        \"You are an expert medical information extraction system. Analyze the provided radiology report text. \"\n",
        "                        \"Your task is to identify and extract two specific pieces of information: \"\n",
        "                        \"1. The single **primary diagnosis** the radiologist seems to be considering most strongly (e.g., from the 'Impression' section or explicitly stated). If multiple possibilities are listed with equal emphasis, choose the first one mentioned or the most likely one based on common patterns. If no clear primary diagnosis is stated, return null or an empty string for this field. \"\n",
        "                        \"2. A comprehensive list of distinct **imaging findings** described in the report (e.g., 'ring enhancement', 'T2 hyperintensity', 'mass effect', 'periventricular lesions', 'cerebellar atrophy'). Extract specific, descriptive findings. \"\n",
        "                        \"Return this information strictly as a JSON object with exactly two keys: 'primary_diagnosis' (string or null) and 'imaging_findings' (a list of strings). Output ONLY the JSON object and nothing else.\\n\"\n",
        "                        \"Example Input: 'Findings: Multiple T2 bright lesions in white matter. Contrast shows ring enhancement in one frontal lesion. Impression: Suggestive of Multiple Sclerosis.'\\n\"\n",
        "                        \"Example Output: {\\\"primary_diagnosis\\\": \\\"Multiple Sclerosis\\\", \\\"imaging_findings\\\": [\\\"Multiple T2 bright lesions in white matter\\\", \\\"ring enhancement in one frontal lesion\\\"]}\"\n",
        "                    ),\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"Extract the primary diagnosis and key imaging findings from this radiology report:\\n\\n--- START REPORT ---\\n{report_text}\\n--- END REPORT ---\\n\\nOutput only a JSON object with 'primary_diagnosis' and 'imaging_findings' keys.\",\n",
        "                }\n",
        "            ],\n",
        "            model=groq_model_name,\n",
        "            temperature=0.0, # Deterministic extraction\n",
        "            max_tokens=450,  # Adjusted token limit\n",
        "            response_format={\"type\": \"json_object\"}, # Explicitly request JSON\n",
        "        )\n",
        "        response_content = chat_completion.choices[0].message.content\n",
        "        # print(f\"   Groq raw JSON response: {response_content}\") # Debugging line\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        try:\n",
        "            parsed_json = json.loads(response_content)\n",
        "            if not isinstance(parsed_json, dict):\n",
        "                print(f\"   Warning: Groq response was not a dictionary as expected. Type: {type(parsed_json)}\")\n",
        "                return default_return\n",
        "\n",
        "            # Extract, validate, and clean the diagnosis\n",
        "            diagnosis_raw = parsed_json.get(\"primary_diagnosis\")\n",
        "            final_diagnosis = str(diagnosis_raw).strip() if diagnosis_raw and isinstance(diagnosis_raw, str) else None\n",
        "\n",
        "            # Extract, validate, and clean the findings list\n",
        "            findings_raw = parsed_json.get(\"imaging_findings\", [])\n",
        "            if isinstance(findings_raw, list):\n",
        "                # Filter out non-strings, strip whitespace, ensure uniqueness (case-insensitive check), sort\n",
        "                seen_lower = set()\n",
        "                cleaned_findings = []\n",
        "                for f in findings_raw:\n",
        "                    if isinstance(f, str) and f.strip():\n",
        "                         f_stripped = f.strip()\n",
        "                         if f_stripped.lower() not in seen_lower:\n",
        "                              cleaned_findings.append(f_stripped)\n",
        "                              seen_lower.add(f_stripped.lower())\n",
        "                final_findings = sorted(cleaned_findings)\n",
        "            else:\n",
        "                print(f\"   Warning: 'imaging_findings' from Groq was not a list. Type: {type(findings_raw)}\")\n",
        "                final_findings = [] # Default to empty list if not a list\n",
        "\n",
        "            result = {\"primary_diagnosis\": final_diagnosis, \"imaging_findings\": final_findings}\n",
        "            print(f\"✅ Extracted via Groq: Diagnosis='{result['primary_diagnosis']}', Findings={result['imaging_findings']}\")\n",
        "            return result\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"   Warning: Failed to parse JSON response from Groq for diagnosis/findings: {response_content}\")\n",
        "            return default_return\n",
        "        except Exception as e_parse:\n",
        "            print(f\"   Error processing Groq JSON content: {e_parse}\")\n",
        "            return default_return\n",
        "\n",
        "    except Exception as e_api:\n",
        "        print(f\"❌ Error calling Groq API for diagnosis/finding extraction: {e_api}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return default_return\n",
        "\n",
        "# --- Optional: Test the updated Groq Extraction Function ---\n",
        "test_report_for_dx_finding = \"Impression: Occipital hypodensity, likely representing acute stroke.\"\n",
        "print(f\"\\nTesting Diagnosis/Finding Extraction for: '{test_report_for_dx_finding}'\")\n",
        "extracted_dx_fx = extract_impression_and_findings_with_groq(test_report_for_dx_finding)\n",
        "print(f\"Test Extraction Result: {extracted_dx_fx}\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ePyoeFOQ8jJ",
        "outputId": "8e96ae44-d428-4fc8-e8da-bf2664f13546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Diagnosis/Finding Extraction for: 'Impression: Occipital hypodensity, likely representing acute stroke.'\n",
            "Attempting to extract primary diagnosis and imaging findings using Groq LLM...\n",
            "✅ Extracted via Groq: Diagnosis='acute stroke', Findings=['Occipital hypodensity']\n",
            "Test Extraction Result: {'primary_diagnosis': 'acute stroke', 'imaging_findings': ['Occipital hypodensity']}\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3: Define Custom Instruction Strings for Agents\n",
        "These strings contain the detailed operational logic and output requirements for each agent. They will be appended to the default system prompts provided by SmolAgents."
      ],
      "metadata": {
        "id": "5zP3QdrPRPqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 4\n",
        "\n",
        "# --- Custom Instructions for Radiopaedia Expert Agent ---\n",
        "\n",
        "radiopaedia_agent_custom_instructions_text = \"\"\"\n",
        "--- ADDITIONAL INSTRUCTIONS FOR YOUR ROLE (Radiopaedia Expert - CodeAgent) ---\n",
        "You are an expert research assistant. Your specific task is to take a **single primary radiological impression** (provided as the `query` argument), find the most relevant Radiopaedia.org article(s) for it, extract their content, and then return it.\n",
        "\n",
        "You have access to these tools:\n",
        "1. `web_search(query: str)`: Use this to find the URL(s) of Radiopaedia pages.\n",
        "2. `radiopaedia_content_extraction_tool(page_url: str)`: Use this to get the text content from a specific Radiopaedia URL.\n",
        "\n",
        "Your workflow when called with a `query` (which is the primary diagnosis):\n",
        "1.  **Find Radiopaedia URL(s):**\n",
        "    *   Use `web_search_tool` with a targeted search query like \"`query` site:radiopaedia.org\" to find the official Radiopaedia article URL(s) for the given diagnosis.\n",
        "    *   Prioritize finding the single, most comprehensive Radiopaedia page. If multiple relevant pages are found (e.g., main article, specific subtypes), you should select the most relevant one.\n",
        "2.  **Extract Content:**\n",
        "    *   For the selected URL, use `radiopaedia_content_extraction_tool(page_url=\"URL_from_step_1\")` to extract its textual content. Handle potential errors from this tool (e.g., if it returns a string starting with \"Error:\").\n",
        "3. **Summarization:**\n",
        "    * Summarize the information the page content offers on the differential diagnoses of the primary diagnosis in one page. Focus on how the differentials present and how to discern them from the primary diagnosis.\n",
        "4.  **Handling Failures:**\n",
        "    *   If you cannot find a relevant Radiopaedia URL via web search, or if content extraction fails for all selected URLs, return a clear error message like \"Error: Could not find or process a Radiopaedia page for diagnosis '[query]'.\"\n",
        "5.  **Final Output:**\n",
        "    *   Write your report in `final_markdown_string`. Call `final_answer(final_markdown_string)`.\n",
        "\n",
        "**Important Considerations:**\n",
        "*   Generated code can use `json` and `ast` packages. Use `print()` for logging.\n",
        "*   Handle errors robustly at each stage (parsing, tool calls, accessing results).\n",
        "\n",
        "**Final Output:** Write your report in `final_markdown_string`. Call `final_answer(final_markdown_string)`.\n",
        "\"\"\"\n",
        "print(\"Defined: radiopaedia_agent_custom_instructions_text\")\n",
        "\n",
        "# --- Custom Instructions for Internal Reference Expert Agent (CodeAgent Version) ---\n",
        "\n",
        "internal_rag_agent_custom_instructions_text = \"\"\"\n",
        "--- ADDITIONAL INSTRUCTIONS FOR YOUR ROLE (Internal Reference Expert - CodeAgent) ---\n",
        "You are a specialized AI agent implemented as a CodeAgent. Your goal is to analyze a list of **imaging findings** to identify potential differential diagnoses (Ddx) for each of them, using information retrieved from an internal PDF reference library via provided tools.\n",
        "Your final output MUST be a **well-formatted Markdown report** summarizing the potential Ddx identified for each finding, returned via the `final_answer()` function.\n",
        "\n",
        "**Input:**\n",
        "*   The list of findings is passed to you as part of your Task prompt.\n",
        "\n",
        "**Available Tools (for your generated code):**\n",
        "1. `query_internal_references_tool(query: str, top_k: int)`: Searches internal PDFs. Returns a **JSON string** ('results' list or 'error'). Your code must parse this.\n",
        "2. `retrieve_neighboring_chunks_tool(...)`: Gets context around a chunk index. Returns a **JSON string** ('results' list or 'error'). Your code must parse this.\n",
        "\n",
        "**Required Workflow Logic (might need two or more rounds of Python Code Generation):**\n",
        "\n",
        "1.  **Extract Findings List:** Create a manual Python list of all imaging findings from the Task you received.\n",
        "2.  **RAG:** Do RAG for each of the imaging findings to find relevant chunks for each of them. To do so, you can call `query_internal_references_tool(query=query_string, top_k=5)` (retrieve slightly more, e.g., top 5 initially) and expect it to return a JSON to you.\n",
        "4.  **Retrieved Chunks Analysis:**\n",
        "    *    Read the retrieved chunks and think which of those might be talking about different diagnoses relevant to the respected imaging finding.\n",
        "    *    Select the chunks that appear relevant.\n",
        "5.  **Round 2: Retrieve Neighbors for Selected Chunks:**\n",
        "    *   For each of the selected chunks:\n",
        "        *   Call `retrieve_neighboring_chunks_tool` for that index. **Decide dynamically how many neighbors (`num_before`, `num_after`, max 3 each) are needed** based on the initial chunk's relevance or ambiguity (this requires LLM reasoning during code generation).\n",
        "        *   Store and log the neighbor JSON string result associated with the selected chunks. Handle/log errors.\n",
        "6. Read the expanded chunks and see if you find any differential diagnoses relevant to the imaging findings. Do not perform a second round of RAG or do not attempt further looking into the neighbor chunks.\n",
        "7.  **Synthesize and Generate Markdown Report:**\n",
        "    *   Based on the chunks you read, create a final report of all possible differential diagnoses for each of the imaging findings and mention the reasons why. Also cite the source PDF / related chunk numbers for reference.\n",
        "    *   Emphasize and prioritize differential diagnoses that are relevant to multiple of the input imaging findings.\n",
        "    *   Keep your report coherent, concise and relevant.\n",
        "    *   Your report MUST be in Markdown format.\n",
        "8.  **Final Output:** Write your report in `final_markdown_string`. Call `final_answer(final_markdown_string)`.\n",
        "\n",
        "**Important Considerations:**\n",
        "*   Generated code can use `json` and `ast` packages. Use `print()` for logging.\n",
        "*   Handle errors robustly at each stage (parsing, tool calls, accessing results).\n",
        "*   Base Ddx strictly on internal PDF text context.\n",
        "\"\"\"\n",
        "print(\"Defined: internal_rag_agent_custom_instructions_text\")\n",
        "\n",
        "# --- Custom Instructions for Orchestrator Agent (`RadiologyReportAnalyzer` - REVISED for Managed Agent Calls) ---\n",
        "orchestrator_custom_instructions_text = \"\"\"\n",
        "--- HIGH-LEVEL GOAL & RESOURCES (RadiologyReportAnalyzer - CodeAgent) ---\n",
        "You are the top-level Orchestrator CodeAgent. Your goal is to generate differential diagnosis suggestions for a radiologist by analyzing their initial assessment and orchestrating managed expert agents. Your final output MUST be a **Markdown report** string returned via `final_answer()`.\n",
        "\n",
        "**Input:**\n",
        "*   A Python dictionary `input_data_dict` (containing `primary_diagnosis`, `imaging_findings`) available in your execution environment.\n",
        "\n",
        "**Available Resources (Managed Agents - call using `task=`):**\n",
        "1.  `radiopaedia_expert`: Input: diagnosis string via `task=`. Output: related Radiopedia article string.\n",
        "2.  `internal_reference_expert`: Input: findings list string representation via `task=`. Output: Markdown report detailing Ddx for imaging findings.\n",
        "\n",
        "**Required Task (Implement via Python Code Generation):**\n",
        "\n",
        "1.  **Process Input:** Generate code to access `input_data_dict`, extract `primary_diagnosis` and `imaging_findings_list`. Handle errors and missing data robustly. Log extracted values. Set `input_ok` flag. If input is invalid, generate code to call `final_answer` with an error Markdown report.\n",
        "2.  **Delegate Research (Conditional on `input_ok`):** Generate code that proceeds only if input is valid. Initialize variables for agent responses.\n",
        "    *   **Call Radiopaedia Expert:** If `primary_diagnosis`, generate code to call `radiopaedia_expert` using `task=` with the diagnosis query. Store the returned string response. Include error handling and logging.\n",
        "    *   **Call Internal Reference Expert:** If `imaging_findings_list`, generate code to construct the task string (including the string representation of the list) and call `internal_reference_expert` using `task=`. Store the returned Markdown string response. Include error handling and logging.\n",
        "3.  **Synthesize Findings:** Analyze the string responses received from both agents (note that these will be in simple string formats and not JSON). Compare info from the Radiopaedia articles with the internal Ddx report (Markdown). Identify consistencies, conflicts, and noteworthy suggestions. Create a list of concise, actionable suggestion strings on what differentials to consider.\n",
        "4.  **Generate Final Markdown Report:** Generate code to construct the final Markdown report string (`final_report_markdown`). No need to include the original content the agents returned to you, but instead include a Synthesized Suggestions section to talk about possible differential diagnoses to consider. Format clearly.\n",
        "5.  **Verification:** Double check your report to make sure no part is missing or is incomplete. If needed, generate it again.\n",
        "6.  **Final Output:** Generate code to call `final_answer(final_report_markdown)`. The argument MUST be the complete Markdown report string. Import `json` if needed internally by your generated code (e.g., for robust error handling).\n",
        "\n",
        "**Important Considerations:**\n",
        "*   Ensure the syntax of your codes are appropriate. E.g., avoid generating codes that might result in errors such as \"f-string expression part cannot include a backslash\".\n",
        "*   Handle errors robustly at each stage (parsing, tool calls, accessing results).\n",
        "\"\"\"\n",
        "print(\"Defined: orchestrator_custom_instructions_text\")"
      ],
      "metadata": {
        "id": "CQESvmpuRHxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd1d47e-66f2-4d06-e625-95257be17a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined: radiopaedia_agent_custom_instructions_text\n",
            "Defined: internal_rag_agent_custom_instructions_text\n",
            "Defined: orchestrator_custom_instructions_text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4: Define and Customize Agents\n",
        "Initialize the agents using their respective classes (CodingAgent) for Radiopaedia, CodeAgent for Internal Reference and Orchestrator). Then, immediately append the corresponding custom instruction strings to their prompt_templates[\"system_prompt\"]."
      ],
      "metadata": {
        "id": "_q4lAGEjRXGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 4\n",
        "\n",
        "# --- Define and Customize Radiopaedia Expert Agent (CodingAgent) ---\n",
        "radiopaedia_expert_agent = None\n",
        "# Check dependencies (LLM model, tools from Sec 3)\n",
        "if radiopedia_scraping_model and 'radiopaedia_content_extraction_tool' in locals() and web_search_tool:\n",
        "    try:\n",
        "        radiopaedia_expert_agent = CodeAgent(\n",
        "            tools=[radiopaedia_content_extraction_tool],\n",
        "            model=radiopedia_scraping_model,\n",
        "            name=\"radiopaedia_expert\",\n",
        "            add_base_tools=True, # To pass web_search\n",
        "            description=( # Short description for Orchestrator\n",
        "                \"Input: radiological impression string. Action: Finds relevant Radiopaedia URL via web search, extracts content, returns the content with URL or error.\"\n",
        "            ),\n",
        "            max_steps=8, # Increased steps for multi-tool use + summarization thought\n",
        "            verbosity_level=2, # Set to 2 for deep debugging if needed\n",
        "            additional_authorized_imports=['json', 'ast'] # For parsing its input task string\n",
        "        )\n",
        "        # Append custom instructions\n",
        "        if radiopaedia_expert_agent.prompt_templates[\"system_prompt\"]:\n",
        "            radiopaedia_expert_agent.prompt_templates[\"system_prompt\"] += \"\\n\" + radiopaedia_agent_custom_instructions_text\n",
        "            print(\"✅ Radiopaedia Expert Agent defined and system prompt customized.\")\n",
        "        else: print(\"⚠️ Radiopaedia Expert Agent: default system prompt template empty during customization.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error defining/customizing Radiopaedia Expert Agent: {e}\")\n",
        "        radiopaedia_expert_agent = None\n",
        "else:\n",
        "    print(\"⚠️ Skipping Radiopaedia Expert Agent definition due to missing dependencies.\")\n",
        "\n",
        "\n",
        "# --- Define and Customize Internal Reference Expert Agent (CodeAgent) ---\n",
        "internal_reference_expert_agent = None\n",
        "# Check dependencies (LLM model, tools from Sec 3, RAG index from Sec 3)\n",
        "if internal_expert_llm_model and 'query_internal_references_tool' in locals() and 'retrieve_neighboring_chunks_tool' in locals() and pdf_rag_index:\n",
        "    try:\n",
        "        internal_reference_expert_agent = CodeAgent(\n",
        "            model=internal_expert_llm_model,\n",
        "            tools=[query_internal_references_tool, retrieve_neighboring_chunks_tool],\n",
        "            add_base_tools=False, # Explicitly authorize imports needed for its generated code\n",
        "            name=\"internal_reference_expert\",\n",
        "            description=( # Description for Orchestrator\n",
        "                \"Input: task string containing Python list of imaging findings. Action: Generates code to use RAG+neighbor tools for each finding, identifies Ddx & reasons from internal PDFs. Output: JSON string mapping findings to list of {'differential_diagnosis': '...', 'reasoning': '...'}.\"\n",
        "            ),\n",
        "            max_steps=25, # Increased steps for complex coding loop, multiple tool calls per finding\n",
        "            verbosity_level=2, # Set to 2 for deep debugging if needed\n",
        "            additional_authorized_imports=['json', 'ast'] # For parsing its input task string\n",
        "        )\n",
        "        # Append custom instructions\n",
        "        if internal_reference_expert_agent.prompt_templates[\"system_prompt\"]:\n",
        "            internal_reference_expert_agent.prompt_templates[\"system_prompt\"] += \"\\n\" + internal_rag_agent_custom_instructions_text\n",
        "            print(\"✅ Internal Reference Expert Agent (CodeAgent) defined, system prompt customized, 'json' & 'ast' authorized.\")\n",
        "        else: print(\"⚠️ Internal Reference Expert Agent: default system prompt template empty during customization.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error defining/customizing Internal Reference Expert Agent: {e}\")\n",
        "        internal_reference_expert_agent = None\n",
        "else:\n",
        "    print(\"⚠️ Skipping Internal Reference Expert Agent definition due to missing dependencies.\")\n",
        "\n",
        "\n",
        "# --- Define and Customize Orchestrator Agent (`RadiologyReportAnalyzer` - CodeAgent) ---\n",
        "radiology_report_analyzer_agent = None\n",
        "managed_agents_list = [] # List to hold successfully created expert agents\n",
        "if radiopaedia_expert_agent: managed_agents_list.append(radiopaedia_expert_agent)\n",
        "if internal_reference_expert_agent: managed_agents_list.append(internal_reference_expert_agent)\n",
        "\n",
        "# Check if Orchestrator LLM is ready and at least one expert agent was successfully created\n",
        "if orchestrator_llm_model and managed_agents_list:\n",
        "    print(f\"\\nProceeding to define Orchestrator Agent with {len(managed_agents_list)} managed expert agent(s).\")\n",
        "    try:\n",
        "        radiology_report_analyzer_agent = CodeAgent(\n",
        "            model=orchestrator_llm_model,\n",
        "            managed_agents=managed_agents_list, # Pass the instances of subordinate agents\n",
        "            tools=[], # Orchestrator delegates specific tool use\n",
        "            add_base_tools=False, # Authorize needed imports specifically\n",
        "            name=\"RadiologyReportAnalyzer\",\n",
        "            description=( # Orchestrator's own description (less critical as it's top-level)\n",
        "                \"Top-level orchestrator for radiology report analysis. Receives primary diagnosis and findings (as dict string). Directs expert agents to gather info. Synthesizes results into final Ddx suggestions for the overall case. Outputs structured JSON via final_answer().\"\n",
        "            ),\n",
        "            verbosity_level=2, # High verbosity for the main orchestrator\n",
        "            max_steps=15, # Planning, input parsing, 2 main agent calls, synthesis, final_answer\n",
        "            additional_authorized_imports=['json', 'ast'] # For parsing its input task string\n",
        "        )\n",
        "        # Append custom instructions\n",
        "        if radiology_report_analyzer_agent.prompt_templates[\"system_prompt\"]:\n",
        "            radiology_report_analyzer_agent.prompt_templates[\"system_prompt\"] += \"\\n\" + orchestrator_custom_instructions_text\n",
        "            print(\"✅ Radiology Report Analyzer (Orchestrator) Agent defined, system prompt customized, 'json' & 'ast' authorized.\")\n",
        "        else: print(\"⚠️ Orchestrator Agent: default system prompt template empty during customization.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error defining/customizing Radiology Report Analyzer Agent: {e}\")\n",
        "        radiology_report_analyzer_agent = None\n",
        "elif not orchestrator_llm_model:\n",
        "    print(\"⚠️ Skipping Orchestrator Agent definition: Orchestrator LLM was not successfully initialized.\")\n",
        "else: # managed_agents_list is empty\n",
        "    print(\"⚠️ Skipping Orchestrator Agent definition: No subordinate expert agents were successfully created or added. The orchestrator needs managed agents to function.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj2p_97wRULW",
        "outputId": "56aaafe3-29bb-44f9-ced8-d59ba98a1040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Radiopaedia Expert Agent defined and system prompt customized.\n",
            "✅ Internal Reference Expert Agent (CodeAgent) defined, system prompt customized, 'json' & 'ast' authorized.\n",
            "\n",
            "Proceeding to define Orchestrator Agent with 2 managed expert agent(s).\n",
            "✅ Radiology Report Analyzer (Orchestrator) Agent defined, system prompt customized, 'json' & 'ast' authorized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5. Multi-Agent Execution Pipeline\n",
        "With our specialized tools defined (Section 3) and our customized agents configured (Section 4), we now create the function that orchestrates the entire workflow. The run_differential_diagnosis_pipeline function defined below serves as the central engine for our radiology assistant.\n",
        "\n",
        "Its process is as follows:\n",
        "\n",
        "1. **Input**: Takes the raw transcribed text from the user's dictation.\n",
        "\n",
        "2. Information Extraction: Calls the extract_impression_and_findings_with_groq function to parse the transcription into a primary diagnosis (if found) and a list of imaging findings.\n",
        "\n",
        "3. **Task Preparation for Orchestrator**: Constructs the specific task input for the RadiologyReportAnalyzerAgent. This input includes the extracted diagnosis and findings, packaged appropriately (as a string representation of a dictionary, which the Orchestrator is instructed to parse).\n",
        "\n",
        "4. **Orchestrator Invocation**: Executes the radiology_report_analyzer_agent.run() method with the prepared task. The Orchestrator, guided by its comprehensive instructions (appended system prompt), will then:\n",
        "  - Call the radiopaedia_expert agent with the primary diagnosis.\n",
        "  - Call the internal_reference_expert agent with the list of imaging findings.\n",
        "  - Receive the concise summary from Radiopaedia and the structured JSON Ddx list from the internal references agent.\n",
        "  - Synthesize this information.\n",
        "  - Generate overall differential diagnosis suggestions.\n",
        "\n",
        "5. **Output Processing**: Receives the final output from the Orchestrator, which should be a JSON string containing the complete analysis and suggestions.\n",
        "\n",
        "6. **Parsing and Validation**: Parses the Orchestrator's JSON output and performs basic validation to ensure it matches the expected structure.\n",
        "\n",
        "7. **Return Value**: Returns the parsed dictionary containing the comprehensive results or an error string if any step in the pipeline fails.\n",
        "\n",
        "This function encapsulates the entire multi-agent interaction, triggered by the user's transcribed report."
      ],
      "metadata": {
        "id": "z3wzyWNCSOET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# In Section 5\n",
        "\n",
        "# Required imports\n",
        "import json # Keep for potential internal error JSON checking if needed\n",
        "import time\n",
        "from smolagents.agent_types import AgentText # Import AgentText to handle it explicitly\n",
        "\n",
        "def run_differential_diagnosis_pipeline(transcription: str) -> str: # Return type is now string\n",
        "    \"\"\"\n",
        "    Orchestrates the multi-agent pipeline. Expects the Orchestrator agent\n",
        "    to return the final result as a Markdown string via final_answer().\n",
        "\n",
        "    Args:\n",
        "        transcription (str): The transcribed radiology report text.\n",
        "\n",
        "    Returns:\n",
        "        str: If successful, returns the Markdown report string generated by the\n",
        "             Orchestrator agent. If any part fails, returns an error string.\n",
        "    \"\"\"\n",
        "    # --- Input Validation ---\n",
        "    if not transcription or not transcription.strip():\n",
        "        print(\"❌ Pipeline Error: Input transcription is empty.\")\n",
        "        return \"Error: Transcription is empty.\"\n",
        "\n",
        "    # --- Agent Readiness Check ---\n",
        "    if 'radiology_report_analyzer_agent' not in globals() or radiology_report_analyzer_agent is None:\n",
        "        print(\"❌ Pipeline Error: Orchestrator Agent not initialized.\")\n",
        "        return \"Error: Core analysis agent (Orchestrator) is not initialized.\"\n",
        "\n",
        "    print(\"\\n--- 🚀 Starting Differential Diagnosis Pipeline 🚀 ---\")\n",
        "    print(f\"Input Transcription (first 200): '{transcription[:200]}...'\")\n",
        "\n",
        "    # --- Step 1: Extract Diagnosis & Findings ---\n",
        "    print(\"\\n--- Step 1: Extracting Diagnosis & Findings (with Groq) ---\")\n",
        "    extracted_info_dict = extract_impression_and_findings_with_groq(transcription)\n",
        "    # ... (Warnings about missing diagnosis/findings) ...\n",
        "\n",
        "    # --- Step 2: Prepare Task and Args for Orchestrator ---\n",
        "    task_for_orchestrator = (\n",
        "        \"Analyze the radiology case using the data in the `input_data_dict` argument. \"\n",
        "        \"Execute your workflow, call managed agents, synthesize results, \"\n",
        "        \"and return the final analysis as a **Markdown report string** via `final_answer()`.\" # Emphasize Markdown output in task too\n",
        "    )\n",
        "    orchestrator_args = {\"input_data_dict\": extracted_info_dict}\n",
        "    print(\"\\n--- Step 2: Task and Args prepared for Orchestrator Agent ---\")\n",
        "    print(f\"   Argument ('input_data_dict'): {orchestrator_args['input_data_dict']}\")\n",
        "\n",
        "    # --- Step 3: Run the Orchestrator Agent ---\n",
        "    print(\"\\n--- Step 3: Invoking Orchestrator Agent...\")\n",
        "    start_time = time.time()\n",
        "    final_orchestrator_output = None # Can be AgentText, str, or None\n",
        "\n",
        "    try:\n",
        "        # .run() returns the object passed to final_answer()\n",
        "        final_orchestrator_output = radiology_report_analyzer_agent.run(\n",
        "            task_for_orchestrator,\n",
        "            additional_args=orchestrator_args\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        print(f\"✅ Orchestrator Agent execution completed in {end_time - start_time:.2f} seconds.\")\n",
        "        # print(f\"   Raw output object type from Orchestrator: {type(final_orchestrator_output)}\") # Debug type\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ CRITICAL ERROR during Orchestrator Agent execution: {e}\")\n",
        "        # ... (Get last step info) ...\n",
        "        return f\"Error during Orchestrator run: {str(e)}\"\n",
        "\n",
        "    # --- Step 4: Validate and Return the Orchestrator's Output (expecting Markdown string) ---\n",
        "    print(\"\\n--- Step 4: Validating Orchestrator's Final Output ---\")\n",
        "\n",
        "    # Check if output exists\n",
        "    if final_orchestrator_output is None:\n",
        "        print(\"❌ Pipeline Error: Orchestrator Agent returned None.\")\n",
        "        # ... (Get last step info) ...\n",
        "        return \"Error: Analysis agent returned None output.\"\n",
        "\n",
        "    # Check if it's a string or an AgentText object (which acts like a string)\n",
        "    if isinstance(final_orchestrator_output, (str, AgentText)):\n",
        "        # Convert AgentText to a plain string if necessary\n",
        "        final_markdown_report = str(final_orchestrator_output)\n",
        "\n",
        "        if not final_markdown_report.strip():\n",
        "             print(\"❌ Pipeline Error: Orchestrator Agent returned an empty string.\")\n",
        "             return \"Error: Analysis agent returned an empty report string.\"\n",
        "        else:\n",
        "             print(\"✅ Successfully received Markdown report string from Orchestrator.\")\n",
        "             print(\"--- Differential Diagnosis Pipeline Completed Successfully 🎉 ---\")\n",
        "             return final_markdown_report # Return the Markdown string\n",
        "    else:\n",
        "        # Output was not a string or AgentText, report error\n",
        "        print(f\"❌ Pipeline Error: Orchestrator Agent returned type {type(final_orchestrator_output)}, expected string or AgentText.\")\n",
        "        print(f\"   Raw output received: {str(final_orchestrator_output)[:500]}...\")\n",
        "        return f\"Error: Analysis agent returned unexpected output type ({type(final_orchestrator_output)}).\""
      ],
      "metadata": {
        "id": "Glabg8HuRbGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# --- Example Usage Cell (for testing Section 5 directly) ---\n",
        "# (Keep the example usage block commented out, but update it to reflect the new input/output)\n",
        "\n",
        "sample_report_for_pipeline_test_revised = \"\"\"\n",
        "HISTORY: 65yo female with visual disturbance with PMH of Alzheimer's disease.\n",
        "FINDINGS: Left occipital hypodensity.\n",
        "IMPRESSION: Findings are highly suspicious for stroke.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n--- ### RUNNING PIPELINE TEST ### ---\")\n",
        "# Ensure dependent variables (agents, etc.) are not None before running\n",
        "all_systems_go_revised = (\n",
        "    orchestrator_llm_model is not None and\n",
        "    radiopedia_scraping_model is not None and # For radiopaedia expert\n",
        "    internal_expert_llm_model is not None and # For internal ref expert\n",
        "    web_search_tool is not None and\n",
        "    'radiopaedia_content_extraction_tool' in locals() and # Tool check\n",
        "    'query_internal_references_tool' in locals() and # Tool check\n",
        "    'retrieve_neighboring_chunks_tool' in locals() and # Tool check\n",
        "    radiopaedia_expert_agent is not None and\n",
        "    internal_reference_expert_agent is not None and\n",
        "    radiology_report_analyzer_agent is not None and\n",
        "    pdf_rag_index is not None # RAG system check\n",
        ")\n",
        "\n",
        "# --- Example Usage Cell (Commented Out) ---\n",
        "# (Update the printing part to handle the string output)\n",
        "print(\"\\n--- ### RUNNING REVISED PIPELINE TEST (Expecting Markdown) ### ---\")\n",
        "if all_systems_go_revised: # Check dependencies\n",
        "    pipeline_test_result_markdown = run_differential_diagnosis_pipeline(sample_report_for_pipeline_test_revised)\n",
        "    print(\"\\n--- ### REVISED PIPELINE TEST RESULT (MARKDOWN) ### ---\")\n",
        "    if pipeline_test_result_markdown.startswith(\"Error:\"):\n",
        "        print(f\"Pipeline Test Error: {pipeline_test_result_markdown}\")\n",
        "    else:\n",
        "        # Print the Markdown report\n",
        "        print(pipeline_test_result_markdown)\n",
        "else:\n",
        "    print(\"⚠️ SKIPPING REVISED PIPELINE TEST: Check component initialization.\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "FvNNJ2zjTCPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6. Advanced GUI (Integrated Workflow)\n",
        "This final section brings all our components together into a single, interactive Gradio application. This interface will allow a radiologist to:\n",
        "\n",
        "1. Input a Report:\n",
        "  - Record their report dictation using a microphone.\n",
        "  - Alternatively, type their report directly into a textbox or edit the transcription.\n",
        "\n",
        "2. Transcribe: Convert the audio to text using Whisper (if audio was provided).\n",
        "\n",
        "3. Analyze: Send the (potentially edited) report text to our multi-agent system (run_differential_diagnosis_pipeline).\n",
        "\n",
        "4. View Results:\n",
        "Display the comprehensive Markdown report generated by the Orchestrator agent, which includes:\n",
        "  - A summary of the input diagnosis and findings.\n",
        "  - The concise summary from Radiopaedia regarding the primary diagnosis.\n",
        "  - The detailed Markdown report from the Internal Reference Expert on Ddx for different findings.\n",
        "  - The Orchestrator's final synthesized differential diagnosis suggestions.\n",
        "\n",
        "The UI will use tabs and appropriate components for a clear presentation of the workflow and its outputs.\n"
      ],
      "metadata": {
        "id": "R7fKSszNeL6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Section 7\n",
        "\n",
        "# Ensure Gradio, json, time are imported (usually in Section 1)\n",
        "import gradio as gr\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import soundfile as sf  # Make sure to pip install soundfile\n",
        "\n",
        "print(\"Setting up Advanced Gradio Interface (Revised Audio Handling)...\")\n",
        "\n",
        "# Create a directory to store permanent audio files\n",
        "os.makedirs(\"saved_audio\", exist_ok=True)\n",
        "\n",
        "# --- Define UI Theme (Optional but recommended) ---\n",
        "theme = gr.themes.Default(\n",
        "    primary_hue=gr.themes.colors.blue,\n",
        "    secondary_hue=gr.themes.colors.neutral\n",
        ").set(\n",
        "    button_primary_background_fill=\"*primary_500\",\n",
        "    button_primary_background_fill_hover=\"*primary_600\",\n",
        "    button_primary_text_color=\"white\",\n",
        "    button_secondary_background_fill=\"*neutral_200\",\n",
        "    button_secondary_background_fill_hover=\"*neutral_300\",\n",
        "    button_secondary_text_color=\"*neutral_700\",\n",
        ")\n",
        "\n",
        "# CSS for styling the output area\n",
        "css_custom = \"\"\"\n",
        "    #final-report-display div { max-height: 70vh; overflow-y: auto; border: 1px solid #e0e0e0; padding: 10px; background-color: #f9f9f9; border-radius: 4px; }\n",
        "    #report-text-input textarea { font-size: 1.05em; line-height: 1.5; }\n",
        "    #status-area p { font-style: italic; color: #555; }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=theme, title=\"Radiology Multi-Agent Assistant\", css=css_custom) as advanced_radiology_gui:\n",
        "    gr.Markdown(\n",
        "        \"# 🧠 Advanced Radiology Report Assistant with Multi-Agent AI 🔬\"\n",
        "        \"\\n*Powered by SmolAgents, Whisper, and LLMs*\"\n",
        "    )\n",
        "\n",
        "    # This variable will store the current audio data\n",
        "    current_audio_data = gr.State(value=None)\n",
        "\n",
        "    # --- This Textbox will hold the current report text for editing and analysis ---\n",
        "    current_report_text_display = gr.Textbox(\n",
        "        label=\"📝 Report Text (Type, Paste, or Edit Transcription)\",\n",
        "        lines=8,\n",
        "        placeholder=\"Your report text will appear here. You can type directly or edit the text after transcription.\",\n",
        "        interactive=True, # User can edit this box\n",
        "        elem_id=\"report-text-input\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3): # Main interaction column\n",
        "            gr.Markdown(\n",
        "                \"**Workflow:**\\n\"\n",
        "                \"1. **Dictate or Type Report:** Use microphone or type directly into the 'Report Text' box above.\\n\"\n",
        "                \"2. **Transcribe (If Voice Used):** After recording, click **'🎤 Transcribe Audio'**. The text appears in the 'Report Text' box.\\n\"\n",
        "                \"3. **Edit Text:** Freely edit the text in the 'Report Text' box.\\n\"\n",
        "                \"4. **Analyze:** Once the report text is ready, click **'💡 Analyze with Multi-Agent AI'**.\\n\"\n",
        "                \"5. **Review Results:** The AI's detailed analysis and suggestions will appear at the bottom.\"\n",
        "            )\n",
        "\n",
        "            # --- Section 1: Input Report (Voice or Text) ---\n",
        "            with gr.Group():\n",
        "                gr.Markdown(\"### Step 1: Provide Your Report\")\n",
        "\n",
        "                # IMPORTANT CHANGE: Changed type to \"numpy\" to get the actual audio data\n",
        "                audio_input = gr.Audio(\n",
        "                    sources=[\"microphone\", \"upload\"],\n",
        "                    type=\"numpy\",  # Changed from \"filepath\" to \"numpy\"\n",
        "                    label=\"🎤 Record Dictation OR Upload Audio File:\",\n",
        "                    elem_id=\"audio-recorder\",\n",
        "                )\n",
        "\n",
        "                # Transcribe Button in its own row below audio\n",
        "                with gr.Row():\n",
        "                    transcribe_button = gr.Button(\n",
        "                        value=\"🎤 Transcribe Audio\",\n",
        "                        variant=\"secondary\",\n",
        "                    )\n",
        "\n",
        "            # --- Section 2: AI Analysis Trigger ---\n",
        "            with gr.Group():\n",
        "                gr.Markdown(\"### Step 2: Perform AI Analysis\")\n",
        "                analyze_button = gr.Button(\n",
        "                    value=\"💡 Analyze Report with Multi-Agent AI\",\n",
        "                    variant=\"primary\",\n",
        "                )\n",
        "\n",
        "            status_update_area = gr.Markdown(\"Status: Ready\", elem_id=\"status-area\")\n",
        "\n",
        "        with gr.Column(scale=2): # Sidebar column\n",
        "            if 'brain_image_url' in globals() and brain_image_url:\n",
        "                brain_caption = brain_image_caption if 'brain_image_caption' in globals() else \"Sample Brain Image\"\n",
        "                gr.Image(value = brain_image_url, label = brain_caption, height=350, show_download_button=False)\n",
        "            else:\n",
        "                gr.Markdown(\"*(Sample CT image could be displayed here if `brain_image_url` is set)*\")\n",
        "\n",
        "            gr.Markdown(\"--- \\n*Disclaimer: This is an educational demonstration tool. **Not for clinical diagnostic use.** Results should be critically reviewed by qualified medical professionals.*\")\n",
        "\n",
        "\n",
        "    # --- Section 3: Output Display Area ---\n",
        "    with gr.Group():\n",
        "        gr.Markdown(\"### Step 3: AI-Generated Report & Differential Diagnosis Suggestions\")\n",
        "        final_markdown_report_output = gr.Markdown(\n",
        "            elem_id=\"final-report-display\",\n",
        "            latex_delimiters=[]\n",
        "        )\n",
        "\n",
        "    # --- Define Button Click Actions (Callbacks) ---\n",
        "\n",
        "    # Function to save audio data to a permanent file\n",
        "    def save_audio_to_file(audio_data):\n",
        "        if audio_data is None:\n",
        "            return None\n",
        "\n",
        "        sample_rate, audio_array= audio_data\n",
        "\n",
        "        # Create a unique filename using timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        permanent_path = os.path.join(\"saved_audio\", f\"audio_{timestamp}.wav\")\n",
        "        # Save the audio data directly\n",
        "        try:\n",
        "            sf.write(permanent_path, audio_array, sample_rate)\n",
        "            print(f\"Audio saved permanently to: {permanent_path}\")\n",
        "            return permanent_path\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving audio: {e}\")\n",
        "            return None\n",
        "\n",
        "    # 1. Audio Recording Event Handler - Save the audio data when it's recorded\n",
        "    def on_audio_recorded(audio_data):\n",
        "        if audio_data is None:\n",
        "            return None\n",
        "\n",
        "        # Store the audio data for later use (no saving yet)\n",
        "        return audio_data\n",
        "\n",
        "    # Connect the audio recording event\n",
        "    audio_input.change(\n",
        "        fn=on_audio_recorded,\n",
        "        inputs=[audio_input],\n",
        "        outputs=[current_audio_data]\n",
        "    )\n",
        "\n",
        "    # 2. Transcription Button Callback\n",
        "    def transcribe_and_update_textbox(audio_data, text_currently_in_box):\n",
        "        if audio_data is None:\n",
        "            return \"Status: No audio provided. Please record or upload audio. 🎤\", text_currently_in_box\n",
        "\n",
        "        # First save the audio data to a permanent file\n",
        "        audio_path = save_audio_to_file(audio_data)\n",
        "\n",
        "        if not audio_path:\n",
        "            return \"Status: Failed to save audio. ❌\", text_currently_in_box\n",
        "\n",
        "        # Now transcribe from the permanent file\n",
        "        try:\n",
        "            print(f\"Transcribing audio from: {audio_path}\")\n",
        "            # Adjust this to use your actual transcription function\n",
        "            transcription_result = transcribe_audio(audio_path)\n",
        "\n",
        "            if \"Error:\" in transcription_result:\n",
        "                return f\"Status: Transcription Failed - {transcription_result} ❌\", text_currently_in_box\n",
        "            else:\n",
        "                return \"Status: Transcription complete. You can now edit the text or proceed to analysis. ✅\", transcription_result\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error during transcription: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return f\"Status: {error_msg} ❌\", text_currently_in_box\n",
        "\n",
        "    # Connect the transcribe button\n",
        "    transcribe_button.click(\n",
        "        fn=transcribe_and_update_textbox,\n",
        "        inputs=[current_audio_data, current_report_text_display],\n",
        "        outputs=[status_update_area, current_report_text_display]\n",
        "    )\n",
        "\n",
        "    # 3. Analysis Button Callback\n",
        "    def analyze_report_and_display(report_text_from_textbox):\n",
        "        if not report_text_from_textbox or not report_text_from_textbox.strip():\n",
        "            return (\"Status: Error - Report text is empty. ❌\",\n",
        "                   \"**Analysis Error:** Report text cannot be empty...\")\n",
        "\n",
        "        yield (\"Status: Starting multi-agent analysis... 🔄\",\n",
        "               \"```markdown\\n🤖 **Processing your report...**\\n...\\n✨ Please be patient! ✨\\n```\")\n",
        "\n",
        "        pipeline_output_str = run_differential_diagnosis_pipeline(report_text_from_textbox)\n",
        "\n",
        "        if isinstance(pipeline_output_str, str) and pipeline_output_str.startswith(\"Error:\"):\n",
        "            yield f\"Status: Analysis Failed ❌\", f\"**Pipeline Error:**\\n\\n```text\\n{pipeline_output_str}\\n```\\n\\n...\"\n",
        "        elif isinstance(pipeline_output_str, str):\n",
        "            yield \"Status: Analysis complete! ✅\", pipeline_output_str\n",
        "        else:\n",
        "            yield (\"Status: Analysis completed with unexpected output. ⚠️\"), (f\"**Unexpected Output:** {type(pipeline_output_str)}\\n\\n\"\n",
        "                                                                           f\"Output:\\n```\\n{str(pipeline_output_str)[:500]}\\n```\")\n",
        "\n",
        "    analyze_button.click(\n",
        "        fn=analyze_report_and_display,\n",
        "        inputs=[current_report_text_display],\n",
        "        outputs=[status_update_area, final_markdown_report_output]\n",
        "    )\n",
        "\n",
        "# --- Launch the Advanced GUI ---\n",
        "print(\"\\n🚀 Launching the Advanced Radiology Assistant GUI...\")\n",
        "print(\"   If running in Colab, a public link will appear. Open it in a new tab for best experience (especially microphone access).\")\n",
        "print(\"   Please ensure you **allow microphone access** in your browser when prompted for voice input.\")\n",
        "\n",
        "advanced_radiology_gui.queue().launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uDE4FXuleQNO",
        "outputId": "e05dd6b1-e8ad-46d8-99dc-8ded6507e743"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up Advanced Gradio Interface (Revised Audio Handling)...\n",
            "\n",
            "🚀 Launching the Advanced Radiology Assistant GUI...\n",
            "   If running in Colab, a public link will appear. Open it in a new tab for best experience (especially microphone access).\n",
            "   Please ensure you **allow microphone access** in your browser when prompted for voice input.\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8cbfdc61280451e28f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8cbfdc61280451e28f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio saved permanently to: saved_audio/audio_20250518_185605.wav\n",
            "Transcribing audio from: saved_audio/audio_20250518_185605.wav\n",
            "Transcribing audio file: saved_audio/audio_20250518_185605.wav...\n",
            "Transcription complete.\n",
            "\n",
            "--- 🚀 Starting Differential Diagnosis Pipeline 🚀 ---\n",
            "Input Transcription (first 200): 'Oxybital, hypodensity. The finding is highly suggestive of stroke....'\n",
            "\n",
            "--- Step 1: Extracting Diagnosis & Findings (with Groq) ---\n",
            "Attempting to extract primary diagnosis and imaging findings using Groq LLM...\n",
            "✅ Extracted via Groq: Diagnosis='stroke', Findings=['Oxybital, hypodensity']\n",
            "\n",
            "--- Step 2: Task and Args prepared for Orchestrator Agent ---\n",
            "   Argument ('input_data_dict'): {'primary_diagnosis': 'stroke', 'imaging_findings': ['Oxybital, hypodensity']}\n",
            "\n",
            "--- Step 3: Invoking Orchestrator Agent...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭─────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run - RadiologyReportAnalyzer</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ───────────────────────────────────────╮</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">Analyze the radiology case using the data in the `input_data_dict` argument. Execute your workflow, call </span>       <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">managed agents, synthesize results, and return the final analysis as a **Markdown report string** via </span>          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">`final_answer()`.</span>                                                                                               <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">You have been provided with these additional arguments, that you can access using the keys as variables in your</span> <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">python code:</span>                                                                                                    <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">{'input_data_dict': {'primary_diagnosis': 'stroke', 'imaging_findings': ['Oxybital, hypodensity'\\]}}.</span>           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ InferenceClientModel - Qwen/Qwen2.5-Coder-32B-Instruct ────────────────────────────────────────────────────────╯</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run - RadiologyReportAnalyzer\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mAnalyze the radiology case using the data in the `input_data_dict` argument. Execute your workflow, call \u001b[0m       \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mmanaged agents, synthesize results, and return the final analysis as a **Markdown report string** via \u001b[0m          \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m`final_answer()`.\u001b[0m                                                                                               \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mYou have been provided with these additional arguments, that you can access using the keys as variables in your\u001b[0m \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mpython code:\u001b[0m                                                                                                    \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1m{'input_data_dict': {'primary_diagnosis': 'stroke', 'imaging_findings': ['Oxybital, hypodensity'\\]}}.\u001b[0m           \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                 \u001b[38;2;212;183;2m│\u001b[0m\n",
              "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m InferenceClientModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m───────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Error in generating model output:</span>\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">402</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> Client Error: Payment Required for url: </span>\n",
              "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> (Request ID: </span>\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Root</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">-682a2d4d-36d51b5003d1a98f0763c56e;</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">b08e383c-21ce-4e3e-b03c-98996856ba16</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">)</span>\n",
              "\n",
              "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 2</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\"> more monthly </span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">included credits.</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;31mError in generating model output:\u001b[0m\n",
              "\u001b[1;36m402\u001b[0m\u001b[1;31m Client Error: Payment Required for url: \u001b[0m\n",
              "\u001b[4;94mhttps://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions\u001b[0m\u001b[1;31m \u001b[0m\u001b[1;31m(\u001b[0m\u001b[1;31mRequest ID: \u001b[0m\n",
              "\u001b[1;33mRoot\u001b[0m\u001b[1;31m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m-682a2d4d-36d51b5003d1a98f0763c56e;\u001b[0m\u001b[93mb08e383c-21ce-4e3e-b03c-98996856ba16\u001b[0m\u001b[1;31m)\u001b[0m\n",
              "\n",
              "\u001b[1;31mYou have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 2\u001b[0m\u001b[1;36m0x\u001b[0m\u001b[1;31m more monthly \u001b[0m\n",
              "\u001b[1;31mincluded credits.\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 0.38 seconds]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2m[Step 1: Duration 0.38 seconds]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ CRITICAL ERROR during Orchestrator Agent execution: Error in generating model output:\n",
            "402 Client Error: Payment Required for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-682a2d4d-36d51b5003d1a98f0763c56e;b08e383c-21ce-4e3e-b03c-98996856ba16)\n",
            "\n",
            "You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.\n"
          ]
        }
      ]
    }
  ]
}